{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks <a class=\"anchor\" id=\"top\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was written by following the textbook of  Aurélien Géron's *Hands-On Machine Learning with Scikit-Learn and TensorFlow*, along with associated datasets ([Link to Github Repo](https://github.com/ageron/handson-ml/)). The contents in this notebook are my notes from reading the textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook by Justin Bandoro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key idea behind artificial neural networks (ANNs) is inspiration from the brain's architecture. ANNs have become quite different from their biological counterpart over time, and are at the very core of Deep Learning. They are versatile, powerful, and scalable, making them ideal to tackle large and highly complex Machine Learning tasks such as classifying billions of images, powering speech recognition services, and recommending the best videos to watch.\n",
    "\n",
    "In this chapter we will introduce ANN architecture and present Multi-Layer Perceptrons (MLPs)and implement using TensorFlow for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1. Background <a class=\"anchor\" id=\"background\"></a>](#1.-Background-<a-class=\"anchor\"-id=\"background\"></a>)\n",
    "* [From Biological to Artificial Neurons](#From-Biological-to-Artificial-Neurons)\n",
    "    * [Biological Neurons](#Biological-Neurons)\n",
    "    * [Logical Computations with Neurons](#Logical-Computations-with-Neurons)\n",
    "    * [The Perceptron](#The-Perceptron)\n",
    "\t* [Multi-Layer Perceptron and Backpropagation](#Multi-Layer-Perceptron-and-Backpropagation)\n",
    "\t* [Activation Functions](#Activation-Functions)\n",
    "* [2. Training an MLP with TensorFlow API <a class=\"anchor\" id=\"mlp\"></a>](#2.-Training-an-MLP-with-TensorFlow-API-<a-class=\"anchor\"-id=\"mlp\"></a>)\n",
    "* [3. Training a DNN with Plain TensorFlow <a class=\"anchor\" id=\"dnn\"></a>](#3.-Training-a-DNN-with-Plain-TensorFlow-<a-class=\"anchor\"-id=\"dnn\"></a>)\n",
    "\t* [Construction Phase](#Construction-Phase)\n",
    "\t* [Execution Phase](#Execution-Phase)\n",
    "\t* [Using the Neural Network for Predictions](#Using-the-Neural-Network-for-Predictions)\n",
    "* [4. Fine-Tuning Neural Network Hyperparameters <a class=\"anchor\" id=\"hyperparameters\"></a>](#4.-Fine-Tuning-Neural-Network-Hyperparameters-<a-class=\"anchor\"-id=\"hyperparameters\"></a>)\n",
    "\t* [Number of Hidden Layers](#Number-of-Hidden-Layers)\n",
    "\t* [Number of Neurons per Hidden Layer](#Number-of-Neurons-per-Hidden-Layer)\n",
    "\t* [Activation Functions](#Activation-Functions)\n",
    "* [5. Revised Calling Methods <a class=\"anchor\" id=\"new\"></a>](#5.-Revised-Calling-Methods-<a-class=\"anchor\"-id=\"new\"></a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.io as sio\n",
    "from matplotlib import cm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing TensorBoard in Jupyter\n",
    "Quick script to view our graphs in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = b\"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:350px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:800px;height:400px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Background <a class=\"anchor\" id=\"background\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Biological to Artificial Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANNs were first introduced in 1943 with a simplified computational model of how biological neurons could work together to perform complex tasks using **propositional logic**. \n",
    "\n",
    "There was a resurgence in the 1980s as new techniques and better training methods were developed. Though in the 1990s the powerful Machine Learning alternatives such as Support Vector Machines and Random Forests were favored by most researchers since they had better results and stronger theoretical foundation.\n",
    "\n",
    "Why are ANNs advantageous?\n",
    "* ANNs outperform other ML techniques on very large and complex problems\n",
    "* Tremendous increase in computing power and GPU architecture can be leveraged\n",
    "* Training algorithms have been improved with tweaks since the 1990s\n",
    "* Although the fear that ANNs would get stuck in local optima was widespread, it turns out that this is rare in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biological Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neurons in animal brains are composed of a cell body containing the nucleus and most of the cell's complex components, and many branching extensions called dendrites, plus one very long extension called the axon. The axon's length may be a few times longer than the cell body or up to ten thousands times longer. Near its extremity the axon splits off into many branches called telodrendria, and at the tip of these branches are minuscule structures called synaptic terminals (synapses) which are connected to the dendrites of other neurons. Neurons receive short electrical impulses called signals from other neurons via these synapses. When a neuron receives a sufficient number of signals from other neurons within a few milliseconds, it fires its own signals.\n",
    "\n",
    "<img src='bioneuron.png'>\n",
    "\n",
    "Neurons are organized in a vast network of billions of neurons, each neuron typically connected to thousands of other neurons. Complex computations can be performed by a vast network of fairly simple neurons. Biological neurons are also organized in consecutive layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logical Computations with Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model of an artificial neuron has one or more binary (on/off) inputs and one binary output. The neuron simply activates its output when more than a certain number of its inputs are active. With these simple neurons you can construct a network capable of handling logical propositions.\n",
    "\n",
    "<img src='logicneuron.png'>\n",
    "\n",
    "* The first network on the left is the identity function: if neuron A is activated, then neuron C gets activated as well (since it receives 2 input signals from neuron A). If neuron A is off, neuron C is also off.\n",
    "* The second network is a logical AND gate: neuron C is activated only when both neurons A and B are activated (a single signal from each is not enough to activate C).\n",
    "* The third network is a logical OR gate: neuron C gets activated if either neuron A or B is activated or if both are activated.\n",
    "* The last network is a bit more complex: neuron C is activated only if neuron A is active and if neuron B is off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Perceptron is the simplest ANN architecture. It is based on a linear threshold unit (LTU): the inputs and output are now numbers (instead of binary on/off) and each input connection is associated with a weight. The LTU computes a weighted sum of the inputs:\n",
    "\n",
    "$z = w_1x_1 + w_2x_2 + \\dots + w_nx_n = \\textbf{w}^T\\cdot\\textbf{x}$\n",
    "\n",
    "Then a step function is applied to the sum and outputs the result:\n",
    "\n",
    "$h_{\\textbf{w}}(\\textbf{x})=step(z)=step(\\textbf{w}^T\\cdot\\textbf{x})$\n",
    "\n",
    "<img src='ltu.png'>\n",
    "\n",
    "The most common step function is a Heaviside step function and sign step function:\n",
    "\n",
    "$heaviside(z) = \\left\\{\n",
    "\\begin{array}{l,c,l}\n",
    "      0,& if& z <  0 \\\\\n",
    "      1, &if  z \\geq  0 \\\\\n",
    "\\end{array} \n",
    "\\right.$\n",
    "\n",
    "$sign(z) = \\left\\{\n",
    "\\begin{array}{l,c,l}\n",
    "      -1,& if& z <  0 \\\\\n",
    "      0, &if & z =  0 \\\\\n",
    "      1, & if& z >  0 \\\\\n",
    "\\end{array} \n",
    "\\right.$\n",
    "\n",
    "A single LTU can be used for simple linear binary classification. It computes a linear combination of the inputs and if the result exceeds a threshold, it outputs the positive class or else outputs the negative class (just like Logistic Regression classifier or a linear SVM). Training a LTU means finding the right values of $\\textbf{w}$.\n",
    "\n",
    "A Perceptron is composed of a single layer of LTUs, with each neuron connected to all of the inputs. These connections are represented with special neurons called input neurons: they output whatever is fed in. There is also a special bias neuron that just inputs 1 all of the time.\n",
    "\n",
    "<img src='perceptron.png'>\n",
    "\n",
    "How is a perceptron trained? Hebb's rule is that when a biological neuron triggers another, the connection between the two neurons is stronger. The weight between 2 neurons is increased when they have the same output. Perceptrons are trained such that it does not reinforce connections that lead to the wrong output. The Perceptron is fed one training instance at a time, and for each instance it makes its predictions. For every output neuron that produced a wrong prediction, it reinforces the connection weight from the inputs that would have contributed to the correct prediction.\n",
    "\n",
    "$w_{i,j}^{(next step)} = w_{i,j} + \\eta(\\hat{y_j} - y_j)x_i$\n",
    "\n",
    "\n",
    "* $w_{i,j}$ is the connection weight between the i$^{th}$ input neuron and the j$^{th}$ output neuron\n",
    "* $x_i$ is the i$^{th}$ value of the current training instance\n",
    "* $\\hat{y_j}$ is the output of the j$^{th}$ output neuron for the current training instance\n",
    "* $\\eta$ is the learning rate\n",
    "\n",
    "The decision boundary of each output neuron is linear, so Perceptrons are incapable of learning complex patterns (just like Logistic Regression classifiers). However, if the training instances are linearly separable, it will converge to a solution.\n",
    "\n",
    "`sklearn` provides a Perceptron class that implements a single LTU network. We show below on the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Justin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/Justin/anaconda3/lib/python3.6/site-packages/matplotlib/contour.py:967: UserWarning: The following kwargs were not used by contour: 'linewidth'\n",
      "  s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1331820f0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAEOCAYAAAA9quuTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13bbdb908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Load iris\n",
    "iris = load_iris()\n",
    "X = iris.data[:,(2,3)] #petal length and width\n",
    "y = (iris.target==0).astype(np.int) # whether Iris Setosa\n",
    "\n",
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X,y)\n",
    "x0, x1 = np.meshgrid(np.linspace(0, 8, 500).reshape(-1, 1),\n",
    "                    np.linspace(0, 3.5, 200).reshape(-1, 1),\n",
    "                    )\n",
    "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "\n",
    "# Plot predictions\n",
    "y_pred = per_clf.predict(X_new).reshape(x0.shape)\n",
    "\n",
    "fig,ax = plt.subplots(1,figsize=[10,4])\n",
    "ax.plot(X[y==1, 0], X[y==1, 1], \"g^\", label=\"Setosa\")\n",
    "ax.plot(X[y==0, 0], X[y==0, 1], \"bs\", label=\"Non-setosa\")\n",
    "from matplotlib.colors import ListedColormap\n",
    "custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
    "ax.contourf(x0, x1, y_pred, cmap=custom_cmap, linewidth=5)\n",
    "ax.set_xlabel(\"Petal length\", fontsize=14)\n",
    "ax.set_ylabel(\"Petal width\", fontsize=14)\n",
    "ax.legend(loc=\"upper left\", fontsize=14,frameon=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we see that the data is linearly separable and the Perceptron works. The Perceptron method strongly resembles Stochastic Gradient Descent, and the class in `sklearn` for `SGDClassifier` is equivalent with the following hyperparameters: `loss=\"perceptron\"`, `learning_rate=\"constant\"`, `eta0=1` (learning rate), and `penalty=None` (no regularization). Unlike Logistic Regression classifiers, Perceptrons do not output a probability and only predict based on hard thresholds.\n",
    "\n",
    "The limitation of Perceptrons can be eliminated by stacking multiple Perceptrons together into an ANN called a **Multi-Layer Perceptron**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron and Backpropagation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='mlp.png'>\n",
    "\n",
    "An MLP has one (passthrough) input layer, one or more layers of LTUs, called **hidden layers** and one final layer of LTUs called the output layer. Every layer except the output layer includes a bias neuron and is fully connected to the next layer. When an ANN has two or more hidden layers, it is called a deep neural network (DNN). The method for training MLPs is known as backpropagation, which is Gradient Descent using reverse-mode autodiff.\n",
    "\n",
    "For each training instance, the algorithm feeds it to the network and computes the output of every neuron in each consecutive layer (this is the forward pass just like when making predictions). Then it measures the network's output error (i.e. the difference between the desired output and the actual output of the network) and it computes how much each neuron in the last hidden layer contributed to each output neuron's error. It then proceeds to measure how much of these error contributions came from each neuron in the previous hidden layer, and so on until the algorithm reaches the input layer. The reverse path, measures the gradient across all the connection weights in the network by propagating the error gradient backward in the work. The last step of the backpropagation is a Gradient Descent step on all the connection weights in the network, using the error gradients measured earlier.\n",
    "\n",
    "In simpler terms, for each training instance the backpropagation algorithm makes a prediction (forward pass), measures the error, and then goes through each layer in reverse to measure the error contribution from each connection (reverse pass), and finally slightly tweaks the connection weights to reduce the error (Gradient Descent step).\n",
    "\n",
    "In the MLP, the step function is replaced with a logistic function: $\\sigma(z) = 1/(1+\\exp(-z))$ because the step function contains only flat segments, so there is no gradient to work with. While the logistic function has a well-defined nonzero gradient everywhere. This function is known as the **activation function**. Other backpropagation algorithms can use other activation functions instead of logistic function. Two popular ones are:\n",
    "\n",
    "* Hyperbolic tangent function: $\\tanh(z) = 2\\sigma(2z)-1)$, similar to the logistic function it is S-shaped, continuous and differentiable, but the output values range from -1 to 1 instead of 0 to 1, which makes each layer's output more or less normalized about 0 and helps speed up convergence.\n",
    "* ReLU function: $\\max(z,0)$, it is continuous but not differentiable at $z=0$. It works well in practice and has the advantage of being fast to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we show the 4 activation functions previously discussed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Derivatives')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAE/CAYAAAB4o6baAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIUwkyZcQQgghhIn+H6JGW3JCo6BSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12e2ed160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def derivative(f, z, eps=0.000001):\n",
    "    return (f(z + eps) - f(z - eps))/(2 * eps)\n",
    "\n",
    "# Plot functions and their derivatives\n",
    "z = np.linspace(-5,5,50)\n",
    "fig,(ax1,ax2) = plt.subplots(1,2, figsize=[10,5])\n",
    "# Step function\n",
    "ax1.plot(z,np.sign(z),lw=2.0,label='Step')\n",
    "ax2.plot(z,derivative(np.sign,z),lw=2.0,label='Step')\n",
    "# Logistic function\n",
    "ax1.plot(z,logit(z),lw=2.0,label='Logistic')\n",
    "ax2.plot(z,derivative( logit,z ),lw=2.0,label='Logistic')\n",
    "# Hyperbolic tan\n",
    "ax1.plot(z,np.tanh(z),lw=2.0,label='Tanh')\n",
    "ax2.plot(z,derivative( np.tanh,z ),lw=2.0,label='Tanh')\n",
    "# ReLU function\n",
    "ax1.plot(z,relu(z),lw=2.0,label='ReLU')\n",
    "ax2.plot(z,derivative( relu,z ),lw=2.0,label='ReLU')\n",
    "ax1.legend();ax1.set_ylim([-1,2])\n",
    "ax1.set_title('Activation Functions');ax2.set_title('Derivatives')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An MLP is often used for classification with each output corresponding to a different binary class (e.g. spam/ham, urgent/non-urgent). When the classes are exclusive (e.g. 0 through 9) the output layer is typically modified by replacing the individual activation functions by a shared Softmax function, where the output of each neuron corresponds to the estimated probability of the corresponding class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training an MLP with TensorFlow API <a class=\"anchor\" id=\"mlp\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to train an MLP with TensorFlow is to use the high-level API `TF.Learn` which is simialr to `sklearn` API. The `DNNClassifier` makes it easy to train a deep neural network with any number of hidden layers, and a softmax output layer with estimated class probabilities. Here the signal flows only in one direction (from inputs to outputs) so this architecture is an example of a feedforward neural network (FNN).\n",
    "\n",
    "Below we show example on the MNIST classification data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# get MNIST data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "X_train = mnist.train.images\n",
    "X_test = mnist.test.images\n",
    "y_train = mnist.train.labels.astype(\"int\")\n",
    "y_test = mnist.test.labels.astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we train a DNN for classification with two hidden layers (one with 300 neurons and one with 100 neurons), and a softmax output layer with 10 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/9f/fp_4v20s1d16d5v3_z7p0b4h0000gn/T/tmpjjxbrrjc\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1156f1f28>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': 42, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/var/folders/9f/fp_4v20s1d16d5v3_z7p0b4h0000gn/T/tmpjjxbrrjc'}\n",
      "WARNING:tensorflow:From /Users/Justin/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:642: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/9f/fp_4v20s1d16d5v3_z7p0b4h0000gn/T/tmpjjxbrrjc/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.36404, step = 1\n",
      "INFO:tensorflow:global_step/sec: 366.628\n",
      "INFO:tensorflow:loss = 0.309677, step = 101 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.545\n",
      "INFO:tensorflow:loss = 0.254103, step = 201 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.128\n",
      "INFO:tensorflow:loss = 0.403251, step = 301 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.944\n",
      "INFO:tensorflow:loss = 0.248612, step = 401 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.626\n",
      "INFO:tensorflow:loss = 0.238972, step = 501 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.606\n",
      "INFO:tensorflow:loss = 0.0964612, step = 601 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.214\n",
      "INFO:tensorflow:loss = 0.119384, step = 701 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.259\n",
      "INFO:tensorflow:loss = 0.184879, step = 801 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.328\n",
      "INFO:tensorflow:loss = 0.093465, step = 901 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.814\n",
      "INFO:tensorflow:loss = 0.206881, step = 1001 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.451\n",
      "INFO:tensorflow:loss = 0.187316, step = 1101 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.934\n",
      "INFO:tensorflow:loss = 0.1543, step = 1201 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.99\n",
      "INFO:tensorflow:loss = 0.163595, step = 1301 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.292\n",
      "INFO:tensorflow:loss = 0.0720562, step = 1401 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.699\n",
      "INFO:tensorflow:loss = 0.0723128, step = 1501 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.267\n",
      "INFO:tensorflow:loss = 0.121916, step = 1601 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.479\n",
      "INFO:tensorflow:loss = 0.039761, step = 1701 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.396\n",
      "INFO:tensorflow:loss = 0.152173, step = 1801 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.455\n",
      "INFO:tensorflow:loss = 0.070405, step = 1901 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.064\n",
      "INFO:tensorflow:loss = 0.0662507, step = 2001 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.06\n",
      "INFO:tensorflow:loss = 0.0241838, step = 2101 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.022\n",
      "INFO:tensorflow:loss = 0.0292274, step = 2201 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.527\n",
      "INFO:tensorflow:loss = 0.0513423, step = 2301 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.56\n",
      "INFO:tensorflow:loss = 0.0555448, step = 2401 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.361\n",
      "INFO:tensorflow:loss = 0.0884138, step = 2501 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.296\n",
      "INFO:tensorflow:loss = 0.0315207, step = 2601 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.869\n",
      "INFO:tensorflow:loss = 0.0126636, step = 2701 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.718\n",
      "INFO:tensorflow:loss = 0.0514662, step = 2801 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.208\n",
      "INFO:tensorflow:loss = 0.088122, step = 2901 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.716\n",
      "INFO:tensorflow:loss = 0.0138777, step = 3001 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.903\n",
      "INFO:tensorflow:loss = 0.044173, step = 3101 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.078\n",
      "INFO:tensorflow:loss = 0.0120668, step = 3201 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.573\n",
      "INFO:tensorflow:loss = 0.0452911, step = 3301 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.81\n",
      "INFO:tensorflow:loss = 0.152817, step = 3401 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.071\n",
      "INFO:tensorflow:loss = 0.0838171, step = 3501 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.179\n",
      "INFO:tensorflow:loss = 0.156769, step = 3601 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.876\n",
      "INFO:tensorflow:loss = 0.0343551, step = 3701 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.245\n",
      "INFO:tensorflow:loss = 0.00878235, step = 3801 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.418\n",
      "INFO:tensorflow:loss = 0.152629, step = 3901 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.128\n",
      "INFO:tensorflow:loss = 0.0950618, step = 4001 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.068\n",
      "INFO:tensorflow:loss = 0.0524628, step = 4101 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.221\n",
      "INFO:tensorflow:loss = 0.0629685, step = 4201 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.904\n",
      "INFO:tensorflow:loss = 0.166633, step = 4301 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.742\n",
      "INFO:tensorflow:loss = 0.108088, step = 4401 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.131\n",
      "INFO:tensorflow:loss = 0.0167887, step = 4501 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.079\n",
      "INFO:tensorflow:loss = 0.0170214, step = 4601 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.944\n",
      "INFO:tensorflow:loss = 0.00988497, step = 4701 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.628\n",
      "INFO:tensorflow:loss = 0.0218255, step = 4801 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.921\n",
      "INFO:tensorflow:loss = 0.0958064, step = 4901 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.019\n",
      "INFO:tensorflow:loss = 0.032898, step = 5001 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.217\n",
      "INFO:tensorflow:loss = 0.00692303, step = 5101 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.304\n",
      "INFO:tensorflow:loss = 0.0374796, step = 5201 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.994\n",
      "INFO:tensorflow:loss = 0.0408561, step = 5301 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.861\n",
      "INFO:tensorflow:loss = 0.0703828, step = 5401 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.886\n",
      "INFO:tensorflow:loss = 0.0597546, step = 5501 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.645\n",
      "INFO:tensorflow:loss = 0.0637175, step = 5601 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.942\n",
      "INFO:tensorflow:loss = 0.0142295, step = 5701 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.003\n",
      "INFO:tensorflow:loss = 0.008777, step = 5801 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.771\n",
      "INFO:tensorflow:loss = 0.0868253, step = 5901 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.137\n",
      "INFO:tensorflow:loss = 0.109432, step = 6001 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.828\n",
      "INFO:tensorflow:loss = 0.0131425, step = 6101 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.397\n",
      "INFO:tensorflow:loss = 0.0240843, step = 6201 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.934\n",
      "INFO:tensorflow:loss = 0.085723, step = 6301 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.946\n",
      "INFO:tensorflow:loss = 0.0259363, step = 6401 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.252\n",
      "INFO:tensorflow:loss = 0.00852303, step = 6501 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.681\n",
      "INFO:tensorflow:loss = 0.0227815, step = 6601 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.316\n",
      "INFO:tensorflow:loss = 0.0275877, step = 6701 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0085514, step = 6801 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.356\n",
      "INFO:tensorflow:loss = 0.0113093, step = 6901 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.842\n",
      "INFO:tensorflow:loss = 0.0190613, step = 7001 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.685\n",
      "INFO:tensorflow:loss = 0.00409009, step = 7101 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.175\n",
      "INFO:tensorflow:loss = 0.0582136, step = 7201 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.697\n",
      "INFO:tensorflow:loss = 0.00672715, step = 7301 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.68\n",
      "INFO:tensorflow:loss = 0.0127499, step = 7401 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.467\n",
      "INFO:tensorflow:loss = 0.005338, step = 7501 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.495\n",
      "INFO:tensorflow:loss = 0.0160609, step = 7601 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.051\n",
      "INFO:tensorflow:loss = 0.00499156, step = 7701 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.424\n",
      "INFO:tensorflow:loss = 0.00483353, step = 7801 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.752\n",
      "INFO:tensorflow:loss = 0.00696935, step = 7901 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.892\n",
      "INFO:tensorflow:loss = 0.00272221, step = 8001 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.176\n",
      "INFO:tensorflow:loss = 0.0217708, step = 8101 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.806\n",
      "INFO:tensorflow:loss = 0.0288787, step = 8201 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.262\n",
      "INFO:tensorflow:loss = 0.0539877, step = 8301 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.36\n",
      "INFO:tensorflow:loss = 0.00857862, step = 8401 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.806\n",
      "INFO:tensorflow:loss = 0.00668675, step = 8501 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.777\n",
      "INFO:tensorflow:loss = 0.00526417, step = 8601 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.564\n",
      "INFO:tensorflow:loss = 0.00431127, step = 8701 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.7\n",
      "INFO:tensorflow:loss = 0.00488374, step = 8801 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.333\n",
      "INFO:tensorflow:loss = 0.00250303, step = 8901 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.205\n",
      "INFO:tensorflow:loss = 0.0148685, step = 9001 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.436\n",
      "INFO:tensorflow:loss = 0.00912793, step = 9101 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.574\n",
      "INFO:tensorflow:loss = 0.00432368, step = 9201 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.883\n",
      "INFO:tensorflow:loss = 0.0138446, step = 9301 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.743\n",
      "INFO:tensorflow:loss = 0.0518277, step = 9401 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.564\n",
      "INFO:tensorflow:loss = 0.00607764, step = 9501 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.195\n",
      "INFO:tensorflow:loss = 0.0207135, step = 9601 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.75\n",
      "INFO:tensorflow:loss = 0.0166932, step = 9701 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.537\n",
      "INFO:tensorflow:loss = 0.00487015, step = 9801 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.199\n",
      "INFO:tensorflow:loss = 0.0185824, step = 9901 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.164\n",
      "INFO:tensorflow:loss = 0.0240925, step = 10001 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.223\n",
      "INFO:tensorflow:loss = 0.00462607, step = 10101 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.921\n",
      "INFO:tensorflow:loss = 0.0100708, step = 10201 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.475\n",
      "INFO:tensorflow:loss = 0.00573162, step = 10301 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.023\n",
      "INFO:tensorflow:loss = 0.0101062, step = 10401 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.075\n",
      "INFO:tensorflow:loss = 0.00470994, step = 10501 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.904\n",
      "INFO:tensorflow:loss = 0.00745281, step = 10601 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.912\n",
      "INFO:tensorflow:loss = 0.0220603, step = 10701 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.717\n",
      "INFO:tensorflow:loss = 0.0147888, step = 10801 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.644\n",
      "INFO:tensorflow:loss = 0.00258084, step = 10901 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.148\n",
      "INFO:tensorflow:loss = 0.0285976, step = 11001 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.669\n",
      "INFO:tensorflow:loss = 0.0044351, step = 11101 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.44\n",
      "INFO:tensorflow:loss = 0.00119579, step = 11201 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.409\n",
      "INFO:tensorflow:loss = 0.0158182, step = 11301 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.445\n",
      "INFO:tensorflow:loss = 0.00693267, step = 11401 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.376\n",
      "INFO:tensorflow:loss = 0.0174892, step = 11501 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.053\n",
      "INFO:tensorflow:loss = 0.000888462, step = 11601 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.168\n",
      "INFO:tensorflow:loss = 0.0026345, step = 11701 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.749\n",
      "INFO:tensorflow:loss = 0.000522998, step = 11801 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.946\n",
      "INFO:tensorflow:loss = 0.0101293, step = 11901 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.422\n",
      "INFO:tensorflow:loss = 0.000120309, step = 12001 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.952\n",
      "INFO:tensorflow:loss = 0.00283077, step = 12101 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.057\n",
      "INFO:tensorflow:loss = 0.00376223, step = 12201 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.354\n",
      "INFO:tensorflow:loss = 0.00516198, step = 12301 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.287\n",
      "INFO:tensorflow:loss = 0.000395552, step = 12401 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.03\n",
      "INFO:tensorflow:loss = 0.0038692, step = 12501 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.701\n",
      "INFO:tensorflow:loss = 0.000996494, step = 12601 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.537\n",
      "INFO:tensorflow:loss = 0.00522744, step = 12701 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.318\n",
      "INFO:tensorflow:loss = 0.00650308, step = 12801 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.381\n",
      "INFO:tensorflow:loss = 0.00290468, step = 12901 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.353\n",
      "INFO:tensorflow:loss = 0.00306313, step = 13001 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.951\n",
      "INFO:tensorflow:loss = 0.0040113, step = 13101 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.242\n",
      "INFO:tensorflow:loss = 0.00749846, step = 13201 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.151\n",
      "INFO:tensorflow:loss = 0.00422553, step = 13301 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.94\n",
      "INFO:tensorflow:loss = 0.00333589, step = 13401 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.275\n",
      "INFO:tensorflow:loss = 0.00930926, step = 13501 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.998\n",
      "INFO:tensorflow:loss = 0.00580592, step = 13601 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.24\n",
      "INFO:tensorflow:loss = 0.00158466, step = 13701 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.968\n",
      "INFO:tensorflow:loss = 0.00957848, step = 13801 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.902\n",
      "INFO:tensorflow:loss = 0.0029991, step = 13901 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.456\n",
      "INFO:tensorflow:loss = 0.00257565, step = 14001 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.455\n",
      "INFO:tensorflow:loss = 0.0051015, step = 14101 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.504\n",
      "INFO:tensorflow:loss = 0.00931561, step = 14201 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.615\n",
      "INFO:tensorflow:loss = 0.00167436, step = 14301 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.674\n",
      "INFO:tensorflow:loss = 0.00068472, step = 14401 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.783\n",
      "INFO:tensorflow:loss = 0.000823331, step = 14501 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.358\n",
      "INFO:tensorflow:loss = 0.00392992, step = 14601 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.355\n",
      "INFO:tensorflow:loss = 0.00197606, step = 14701 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.49\n",
      "INFO:tensorflow:loss = 0.00111108, step = 14801 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.091\n",
      "INFO:tensorflow:loss = 0.00252097, step = 14901 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.000814515, step = 15001 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.901\n",
      "INFO:tensorflow:loss = 0.00237104, step = 15101 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.494\n",
      "INFO:tensorflow:loss = 0.00227502, step = 15201 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.143\n",
      "INFO:tensorflow:loss = 0.00141252, step = 15301 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.92\n",
      "INFO:tensorflow:loss = 0.00455337, step = 15401 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.349\n",
      "INFO:tensorflow:loss = 0.00491852, step = 15501 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.332\n",
      "INFO:tensorflow:loss = 0.00487903, step = 15601 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.521\n",
      "INFO:tensorflow:loss = 0.0134273, step = 15701 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.244\n",
      "INFO:tensorflow:loss = 0.00312125, step = 15801 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.983\n",
      "INFO:tensorflow:loss = 0.000708232, step = 15901 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.524\n",
      "INFO:tensorflow:loss = 0.00560298, step = 16001 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.197\n",
      "INFO:tensorflow:loss = 0.00430737, step = 16101 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.798\n",
      "INFO:tensorflow:loss = 7.45395e-05, step = 16201 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.849\n",
      "INFO:tensorflow:loss = 0.00280412, step = 16301 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.031\n",
      "INFO:tensorflow:loss = 0.001583, step = 16401 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.145\n",
      "INFO:tensorflow:loss = 0.00205469, step = 16501 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.194\n",
      "INFO:tensorflow:loss = 0.00472116, step = 16601 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.968\n",
      "INFO:tensorflow:loss = 0.00300912, step = 16701 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.658\n",
      "INFO:tensorflow:loss = 0.00221508, step = 16801 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.306\n",
      "INFO:tensorflow:loss = 0.00274078, step = 16901 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.675\n",
      "INFO:tensorflow:loss = 0.00335069, step = 17001 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.849\n",
      "INFO:tensorflow:loss = 0.000582267, step = 17101 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.934\n",
      "INFO:tensorflow:loss = 0.00259225, step = 17201 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.309\n",
      "INFO:tensorflow:loss = 0.000920891, step = 17301 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.896\n",
      "INFO:tensorflow:loss = 0.00217769, step = 17401 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.825\n",
      "INFO:tensorflow:loss = 0.00163418, step = 17501 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.231\n",
      "INFO:tensorflow:loss = 0.000338328, step = 17601 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.166\n",
      "INFO:tensorflow:loss = 0.000893746, step = 17701 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.817\n",
      "INFO:tensorflow:loss = 0.000348846, step = 17801 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.049\n",
      "INFO:tensorflow:loss = 0.00200284, step = 17901 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.563\n",
      "INFO:tensorflow:loss = 0.0012488, step = 18001 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.52\n",
      "INFO:tensorflow:loss = 0.00122258, step = 18101 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.512\n",
      "INFO:tensorflow:loss = 0.00400346, step = 18201 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.96\n",
      "INFO:tensorflow:loss = 0.0154516, step = 18301 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.481\n",
      "INFO:tensorflow:loss = 0.00357402, step = 18401 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.793\n",
      "INFO:tensorflow:loss = 0.00224499, step = 18501 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.543\n",
      "INFO:tensorflow:loss = 0.00348468, step = 18601 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.364\n",
      "INFO:tensorflow:loss = 0.00106254, step = 18701 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.7\n",
      "INFO:tensorflow:loss = 0.00134678, step = 18801 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.343\n",
      "INFO:tensorflow:loss = 0.00304573, step = 18901 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.852\n",
      "INFO:tensorflow:loss = 0.00137681, step = 19001 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.562\n",
      "INFO:tensorflow:loss = 0.000547609, step = 19101 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.128\n",
      "INFO:tensorflow:loss = 0.000463684, step = 19201 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.726\n",
      "INFO:tensorflow:loss = 0.00509027, step = 19301 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.912\n",
      "INFO:tensorflow:loss = 0.000722533, step = 19401 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.669\n",
      "INFO:tensorflow:loss = 0.00281473, step = 19501 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.087\n",
      "INFO:tensorflow:loss = 0.000629583, step = 19601 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.735\n",
      "INFO:tensorflow:loss = 0.000147449, step = 19701 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.102\n",
      "INFO:tensorflow:loss = 0.000430371, step = 19801 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.465\n",
      "INFO:tensorflow:loss = 0.00136521, step = 19901 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.859\n",
      "INFO:tensorflow:loss = 0.0024896, step = 20001 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.156\n",
      "INFO:tensorflow:loss = 0.000431558, step = 20101 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.629\n",
      "INFO:tensorflow:loss = 0.00192564, step = 20201 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.894\n",
      "INFO:tensorflow:loss = 0.000940824, step = 20301 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.836\n",
      "INFO:tensorflow:loss = 0.000245953, step = 20401 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.047\n",
      "INFO:tensorflow:loss = 0.00025361, step = 20501 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.68\n",
      "INFO:tensorflow:loss = 0.00130026, step = 20601 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.47\n",
      "INFO:tensorflow:loss = 0.00123567, step = 20701 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.397\n",
      "INFO:tensorflow:loss = 0.00204745, step = 20801 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.191\n",
      "INFO:tensorflow:loss = 0.00153957, step = 20901 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.987\n",
      "INFO:tensorflow:loss = 0.00241378, step = 21001 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.992\n",
      "INFO:tensorflow:loss = 0.00142351, step = 21101 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.533\n",
      "INFO:tensorflow:loss = 0.00256507, step = 21201 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.955\n",
      "INFO:tensorflow:loss = 0.00106203, step = 21301 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.001\n",
      "INFO:tensorflow:loss = 0.0025859, step = 21401 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.231\n",
      "INFO:tensorflow:loss = 0.000238369, step = 21501 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.9\n",
      "INFO:tensorflow:loss = 0.00158536, step = 21601 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.494\n",
      "INFO:tensorflow:loss = 0.000727434, step = 21701 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.385\n",
      "INFO:tensorflow:loss = 0.000661301, step = 21801 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.322\n",
      "INFO:tensorflow:loss = 0.000490357, step = 21901 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.724\n",
      "INFO:tensorflow:loss = 0.000124842, step = 22001 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.089\n",
      "INFO:tensorflow:loss = 0.000445235, step = 22101 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.029\n",
      "INFO:tensorflow:loss = 0.00133724, step = 22201 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.69\n",
      "INFO:tensorflow:loss = 0.00247763, step = 22301 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.279\n",
      "INFO:tensorflow:loss = 0.00171271, step = 22401 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.085\n",
      "INFO:tensorflow:loss = 0.00149307, step = 22501 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.324\n",
      "INFO:tensorflow:loss = 0.00392994, step = 22601 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.343\n",
      "INFO:tensorflow:loss = 0.000875101, step = 22701 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.384\n",
      "INFO:tensorflow:loss = 0.00118385, step = 22801 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.529\n",
      "INFO:tensorflow:loss = 0.00240292, step = 22901 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.175\n",
      "INFO:tensorflow:loss = 0.000830913, step = 23001 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.429\n",
      "INFO:tensorflow:loss = 0.00284528, step = 23101 (0.253 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 391.324\n",
      "INFO:tensorflow:loss = 0.00224091, step = 23201 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.019\n",
      "INFO:tensorflow:loss = 0.00193402, step = 23301 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.148\n",
      "INFO:tensorflow:loss = 0.000599899, step = 23401 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.142\n",
      "INFO:tensorflow:loss = 0.000690191, step = 23501 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.859\n",
      "INFO:tensorflow:loss = 0.0006689, step = 23601 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.039\n",
      "INFO:tensorflow:loss = 0.000450027, step = 23701 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.592\n",
      "INFO:tensorflow:loss = 0.00181704, step = 23801 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.493\n",
      "INFO:tensorflow:loss = 0.00110625, step = 23901 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.639\n",
      "INFO:tensorflow:loss = 0.000971603, step = 24001 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.178\n",
      "INFO:tensorflow:loss = 0.000599703, step = 24101 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.154\n",
      "INFO:tensorflow:loss = 0.00103672, step = 24201 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.889\n",
      "INFO:tensorflow:loss = 0.000316926, step = 24301 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.749\n",
      "INFO:tensorflow:loss = 0.00197788, step = 24401 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.074\n",
      "INFO:tensorflow:loss = 0.000518455, step = 24501 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.905\n",
      "INFO:tensorflow:loss = 0.000293449, step = 24601 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.472\n",
      "INFO:tensorflow:loss = 0.00114909, step = 24701 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.069\n",
      "INFO:tensorflow:loss = 0.00152487, step = 24801 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.723\n",
      "INFO:tensorflow:loss = 0.00201351, step = 24901 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.485\n",
      "INFO:tensorflow:loss = 0.000152594, step = 25001 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.722\n",
      "INFO:tensorflow:loss = 0.00193388, step = 25101 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.579\n",
      "INFO:tensorflow:loss = 0.00282617, step = 25201 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.057\n",
      "INFO:tensorflow:loss = 0.000192127, step = 25301 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.488\n",
      "INFO:tensorflow:loss = 0.000797401, step = 25401 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.14\n",
      "INFO:tensorflow:loss = 0.00124578, step = 25501 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.804\n",
      "INFO:tensorflow:loss = 0.00119779, step = 25601 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.479\n",
      "INFO:tensorflow:loss = 0.000874612, step = 25701 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.559\n",
      "INFO:tensorflow:loss = 0.00136518, step = 25801 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.041\n",
      "INFO:tensorflow:loss = 0.00184243, step = 25901 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.72\n",
      "INFO:tensorflow:loss = 7.84672e-05, step = 26001 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.482\n",
      "INFO:tensorflow:loss = 0.00103029, step = 26101 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.529\n",
      "INFO:tensorflow:loss = 0.000715368, step = 26201 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.782\n",
      "INFO:tensorflow:loss = 0.000957418, step = 26301 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.553\n",
      "INFO:tensorflow:loss = 0.00165632, step = 26401 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.948\n",
      "INFO:tensorflow:loss = 0.00100959, step = 26501 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.95\n",
      "INFO:tensorflow:loss = 0.000594357, step = 26601 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.207\n",
      "INFO:tensorflow:loss = 3.75124e-05, step = 26701 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.294\n",
      "INFO:tensorflow:loss = 0.000775705, step = 26801 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.108\n",
      "INFO:tensorflow:loss = 0.000904265, step = 26901 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.781\n",
      "INFO:tensorflow:loss = 0.000553487, step = 27001 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.895\n",
      "INFO:tensorflow:loss = 0.00042911, step = 27101 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.276\n",
      "INFO:tensorflow:loss = 0.000641743, step = 27201 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.993\n",
      "INFO:tensorflow:loss = 0.00113445, step = 27301 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.63\n",
      "INFO:tensorflow:loss = 0.000147887, step = 27401 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.737\n",
      "INFO:tensorflow:loss = 0.00149474, step = 27501 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.149\n",
      "INFO:tensorflow:loss = 0.00099866, step = 27601 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.582\n",
      "INFO:tensorflow:loss = 0.000368925, step = 27701 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.05\n",
      "INFO:tensorflow:loss = 0.000700521, step = 27801 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.859\n",
      "INFO:tensorflow:loss = 0.000367836, step = 27901 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.774\n",
      "INFO:tensorflow:loss = 0.00131156, step = 28001 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.416\n",
      "INFO:tensorflow:loss = 0.000550622, step = 28101 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.13\n",
      "INFO:tensorflow:loss = 0.00143182, step = 28201 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.972\n",
      "INFO:tensorflow:loss = 0.000660615, step = 28301 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.188\n",
      "INFO:tensorflow:loss = 0.00102658, step = 28401 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.014\n",
      "INFO:tensorflow:loss = 0.000680939, step = 28501 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.213\n",
      "INFO:tensorflow:loss = 0.000403072, step = 28601 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.815\n",
      "INFO:tensorflow:loss = 0.000918623, step = 28701 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.107\n",
      "INFO:tensorflow:loss = 0.000993003, step = 28801 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.991\n",
      "INFO:tensorflow:loss = 0.000232585, step = 28901 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.545\n",
      "INFO:tensorflow:loss = 0.00192796, step = 29001 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.567\n",
      "INFO:tensorflow:loss = 0.00101591, step = 29101 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.853\n",
      "INFO:tensorflow:loss = 0.00169011, step = 29201 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.05\n",
      "INFO:tensorflow:loss = 0.00108807, step = 29301 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.579\n",
      "INFO:tensorflow:loss = 0.00101428, step = 29401 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.743\n",
      "INFO:tensorflow:loss = 0.000796202, step = 29501 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.706\n",
      "INFO:tensorflow:loss = 0.000337627, step = 29601 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.45\n",
      "INFO:tensorflow:loss = 0.000258813, step = 29701 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.531\n",
      "INFO:tensorflow:loss = 0.000616941, step = 29801 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.787\n",
      "INFO:tensorflow:loss = 0.00074321, step = 29901 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.515\n",
      "INFO:tensorflow:loss = 6.01432e-05, step = 30001 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.283\n",
      "INFO:tensorflow:loss = 0.000580716, step = 30101 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.496\n",
      "INFO:tensorflow:loss = 0.000218506, step = 30201 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.905\n",
      "INFO:tensorflow:loss = 0.000837331, step = 30301 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.195\n",
      "INFO:tensorflow:loss = 0.00138102, step = 30401 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.598\n",
      "INFO:tensorflow:loss = 0.000929428, step = 30501 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.07\n",
      "INFO:tensorflow:loss = 0.00146183, step = 30601 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.811\n",
      "INFO:tensorflow:loss = 0.000773375, step = 30701 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.841\n",
      "INFO:tensorflow:loss = 0.00110586, step = 30801 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.071\n",
      "INFO:tensorflow:loss = 0.00121131, step = 30901 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.029\n",
      "INFO:tensorflow:loss = 0.00107659, step = 31001 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.263\n",
      "INFO:tensorflow:loss = 0.00138425, step = 31101 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.008\n",
      "INFO:tensorflow:loss = 0.000538949, step = 31201 (0.272 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 315.389\n",
      "INFO:tensorflow:loss = 0.000428765, step = 31301 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.988\n",
      "INFO:tensorflow:loss = 0.000609493, step = 31401 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.233\n",
      "INFO:tensorflow:loss = 0.00025601, step = 31501 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.518\n",
      "INFO:tensorflow:loss = 8.65842e-05, step = 31601 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.943\n",
      "INFO:tensorflow:loss = 0.000604256, step = 31701 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.831\n",
      "INFO:tensorflow:loss = 9.59904e-05, step = 31801 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.314\n",
      "INFO:tensorflow:loss = 0.00079322, step = 31901 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.611\n",
      "INFO:tensorflow:loss = 0.000262161, step = 32001 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.686\n",
      "INFO:tensorflow:loss = 0.000368648, step = 32101 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.869\n",
      "INFO:tensorflow:loss = 0.00113988, step = 32201 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.847\n",
      "INFO:tensorflow:loss = 0.00038782, step = 32301 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.95\n",
      "INFO:tensorflow:loss = 0.000149349, step = 32401 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.329\n",
      "INFO:tensorflow:loss = 0.000642526, step = 32501 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.338\n",
      "INFO:tensorflow:loss = 0.000118947, step = 32601 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.216\n",
      "INFO:tensorflow:loss = 0.00136909, step = 32701 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.186\n",
      "INFO:tensorflow:loss = 0.00105548, step = 32801 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.623\n",
      "INFO:tensorflow:loss = 0.0003802, step = 32901 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.7\n",
      "INFO:tensorflow:loss = 0.000608995, step = 33001 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.689\n",
      "INFO:tensorflow:loss = 0.0019107, step = 33101 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.762\n",
      "INFO:tensorflow:loss = 0.000916178, step = 33201 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.534\n",
      "INFO:tensorflow:loss = 0.000244862, step = 33301 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.473\n",
      "INFO:tensorflow:loss = 0.00129239, step = 33401 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.079\n",
      "INFO:tensorflow:loss = 0.000242947, step = 33501 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.659\n",
      "INFO:tensorflow:loss = 0.000883703, step = 33601 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.357\n",
      "INFO:tensorflow:loss = 0.000904791, step = 33701 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.776\n",
      "INFO:tensorflow:loss = 0.00107614, step = 33801 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.833\n",
      "INFO:tensorflow:loss = 0.00107961, step = 33901 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.953\n",
      "INFO:tensorflow:loss = 0.000613074, step = 34001 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.32\n",
      "INFO:tensorflow:loss = 0.00085227, step = 34101 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.533\n",
      "INFO:tensorflow:loss = 0.00112095, step = 34201 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.908\n",
      "INFO:tensorflow:loss = 0.000104322, step = 34301 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.961\n",
      "INFO:tensorflow:loss = 0.000506521, step = 34401 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.614\n",
      "INFO:tensorflow:loss = 0.000799231, step = 34501 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.648\n",
      "INFO:tensorflow:loss = 0.000381998, step = 34601 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.098\n",
      "INFO:tensorflow:loss = 0.00197285, step = 34701 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.897\n",
      "INFO:tensorflow:loss = 0.00050132, step = 34801 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.811\n",
      "INFO:tensorflow:loss = 0.000430059, step = 34901 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.15\n",
      "INFO:tensorflow:loss = 0.000284109, step = 35001 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.409\n",
      "INFO:tensorflow:loss = 0.0012278, step = 35101 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.349\n",
      "INFO:tensorflow:loss = 0.000280491, step = 35201 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.783\n",
      "INFO:tensorflow:loss = 0.000161269, step = 35301 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.891\n",
      "INFO:tensorflow:loss = 0.00105551, step = 35401 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.711\n",
      "INFO:tensorflow:loss = 0.000203097, step = 35501 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.557\n",
      "INFO:tensorflow:loss = 0.000242335, step = 35601 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.871\n",
      "INFO:tensorflow:loss = 0.00086094, step = 35701 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.642\n",
      "INFO:tensorflow:loss = 0.000918586, step = 35801 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.468\n",
      "INFO:tensorflow:loss = 0.000671677, step = 35901 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.757\n",
      "INFO:tensorflow:loss = 0.000370165, step = 36001 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.133\n",
      "INFO:tensorflow:loss = 0.00120145, step = 36101 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.344\n",
      "INFO:tensorflow:loss = 0.000768125, step = 36201 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.066\n",
      "INFO:tensorflow:loss = 0.000106661, step = 36301 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.787\n",
      "INFO:tensorflow:loss = 0.000681248, step = 36401 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.445\n",
      "INFO:tensorflow:loss = 0.000214154, step = 36501 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.005\n",
      "INFO:tensorflow:loss = 0.000239673, step = 36601 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.571\n",
      "INFO:tensorflow:loss = 0.000405055, step = 36701 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.05\n",
      "INFO:tensorflow:loss = 0.000852568, step = 36801 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.155\n",
      "INFO:tensorflow:loss = 0.000667005, step = 36901 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.623\n",
      "INFO:tensorflow:loss = 0.000488099, step = 37001 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.404\n",
      "INFO:tensorflow:loss = 0.000311534, step = 37101 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.766\n",
      "INFO:tensorflow:loss = 0.000358862, step = 37201 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.613\n",
      "INFO:tensorflow:loss = 0.000707558, step = 37301 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.014\n",
      "INFO:tensorflow:loss = 0.000318062, step = 37401 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.7\n",
      "INFO:tensorflow:loss = 0.000298998, step = 37501 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.246\n",
      "INFO:tensorflow:loss = 0.000414938, step = 37601 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.352\n",
      "INFO:tensorflow:loss = 0.000145852, step = 37701 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.004\n",
      "INFO:tensorflow:loss = 0.000346428, step = 37801 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.438\n",
      "INFO:tensorflow:loss = 0.0015781, step = 37901 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.785\n",
      "INFO:tensorflow:loss = 0.000307783, step = 38001 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.361\n",
      "INFO:tensorflow:loss = 0.00120952, step = 38101 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.231\n",
      "INFO:tensorflow:loss = 0.000719946, step = 38201 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.724\n",
      "INFO:tensorflow:loss = 9.19537e-05, step = 38301 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.85\n",
      "INFO:tensorflow:loss = 0.000204637, step = 38401 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.785\n",
      "INFO:tensorflow:loss = 0.000502236, step = 38501 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.988\n",
      "INFO:tensorflow:loss = 0.000743682, step = 38601 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.241\n",
      "INFO:tensorflow:loss = 0.000451052, step = 38701 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.912\n",
      "INFO:tensorflow:loss = 0.000246905, step = 38801 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.887\n",
      "INFO:tensorflow:loss = 0.00129647, step = 38901 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.632\n",
      "INFO:tensorflow:loss = 0.000217024, step = 39001 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.579\n",
      "INFO:tensorflow:loss = 0.000741188, step = 39101 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.122\n",
      "INFO:tensorflow:loss = 0.000570652, step = 39201 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.448\n",
      "INFO:tensorflow:loss = 0.000307514, step = 39301 (0.272 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 368.533\n",
      "INFO:tensorflow:loss = 0.00066551, step = 39401 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.514\n",
      "INFO:tensorflow:loss = 0.000248625, step = 39501 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.901\n",
      "INFO:tensorflow:loss = 0.000750375, step = 39601 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.464\n",
      "INFO:tensorflow:loss = 0.000224784, step = 39701 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.515\n",
      "INFO:tensorflow:loss = 0.00105966, step = 39801 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.327\n",
      "INFO:tensorflow:loss = 0.00136582, step = 39901 (0.278 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into /var/folders/9f/fp_4v20s1d16d5v3_z7p0b4h0000gn/T/tmpjjxbrrjc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00045437.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SKCompat()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = tf.contrib.learn.RunConfig(tf_random_seed=42)\n",
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(X_train)\n",
    "#DNN classifier\n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[300,100],n_classes=10,\n",
    "                                        feature_columns=feature_cols,config=config)\n",
    "dnn_clf = tf.contrib.learn.SKCompat(dnn_clf)\n",
    "dnn_clf.fit(X_train,y_train,batch_size=50,steps=40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/9f/fp_4v20s1d16d5v3_z7p0b4h0000gn/T/tmpjjxbrrjc/model.ckpt-40000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98240000000000005"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = dnn_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred['classes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see above that we achieved a score of over 98% on the test set easily! The TF.Learn library provides its own functions to evaluate models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Justin/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:642: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-11-30-15:16:00\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/9f/fp_4v20s1d16d5v3_z7p0b4h0000gn/T/tmpjjxbrrjc/model.ckpt-40000\n",
      "INFO:tensorflow:Finished evaluation at 2017-11-30-15:16:01\n",
      "INFO:tensorflow:Saving dict for global step 40000: accuracy = 0.9824, global_step = 40000, loss = 0.0707704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9824, 'global_step': 40000, 'loss': 0.070770428}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the neuron layers, based on the ReLU activation function (can be changed by setting `activation_fn` hyperparameter) are all under the hood in the `DNNClassifier`. The output layer relies on the softmax function, and the cost function is cross entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training a DNN with Plain TensorFlow <a class=\"anchor\" id=\"dnn\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use TF's lower level API to have more control over the architecture of the network. We will implement the same model in the last section. The first step is the constructin phase, building the graph. The second is execution, where we will run the graph to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_inputs = 28*28 # number of pixels\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "# Placeholders for training data\n",
    "X = tf.placeholder(tf.float32, shape=(None,n_inputs),name='X')\n",
    "y = tf.placeholder(tf.int64, shape=(None),name='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The placeholder `X` will act as the input layer, during the execution phase it will be replaced with one training batch at a time (all instances of the training batch will be processed simultaneously by the neural network). \n",
    "\n",
    "Next we will create 2 hidden layers and an output layer. The hidden layers are identical besides the number of neurons contained. The output layer uses a ssoftmax activation function instead of a ReLU activation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layer(X,n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs=int(X.get_shape()[1])\n",
    "        stddev = 2/np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal( (n_inputs,n_neurons),stddev=stddev)\n",
    "        W = tf.Variable(init,name='weights')\n",
    "        b = tf.Variable(tf.zeros([n_neurons]),name='biases')\n",
    "        z = tf.matmul(X,W)+b\n",
    "        if activation=='relu':\n",
    "            return tf.nn.relu(z)\n",
    "        else:\n",
    "            return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the steps we are doing in the code above:\n",
    "1. Create a name scope using the name of the layer: contains all the computation nodes for the neuron layer.\n",
    "2. Get the number of inputs by looking at the input matrix shape.\n",
    "3. The weight matrix, W, contains the weights for each neurons in the layer and each input. It is initialized using a truncated normal distribution with a standard deviation of $2/ \\sqrt{n_{inputs}}$ which is known to make convergence faster.\n",
    "4. Create a variable, b, for biases initialized all to 0. \n",
    "5. We create a subgraph to compute the vectorized implementation of  $z = X\\cdot W + b$. The weighted sums of the inputs plus the bias term for each and every neuron in the layer, for all instances in the batch in one shot.\n",
    "6. The activation is set to 'relu' if wanted.\n",
    "\n",
    "Now let's create the layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:800px;height:400px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.1624895573440991&quot;).pbtxt = 'node {\\n  name: &quot;X&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 784\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\020\\\\003\\\\000\\\\000,\\\\001\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0714285746216774\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;dnn/hidden1/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dnn/hidden1/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;dnn/hidden1/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dnn/hidden1/truncated_normal/mul&quot;\\n  input: &quot;dnn/hidden1/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/weights&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 784\\n        }\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/weights/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden1/weights&quot;\\n  input: &quot;dnn/hidden1/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/weights/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dnn/hidden1/weights&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/biases&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/biases/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden1/biases&quot;\\n  input: &quot;dnn/hidden1/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/biases/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dnn/hidden1/biases&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden1/biases&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;dnn/hidden1/weights/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dnn/hidden1/MatMul&quot;\\n  input: &quot;dnn/hidden1/biases/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden1/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;,\\\\001\\\\000\\\\000d\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.1154700517654419\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;dnn/hidden2/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dnn/hidden2/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;dnn/hidden2/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dnn/hidden2/truncated_normal/mul&quot;\\n  input: &quot;dnn/hidden2/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/weights&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/weights/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden2/weights&quot;\\n  input: &quot;dnn/hidden2/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/weights/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dnn/hidden2/weights&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 100\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/biases&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/biases/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/hidden2/biases&quot;\\n  input: &quot;dnn/hidden2/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/biases/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dnn/hidden2/biases&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/hidden2/biases&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;dnn/hidden2/weights/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dnn/hidden2/MatMul&quot;\\n  input: &quot;dnn/hidden2/biases/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden2/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;d\\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.20000000298023224\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;dnn/outputs/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dnn/outputs/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;dnn/outputs/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dnn/outputs/truncated_normal/mul&quot;\\n  input: &quot;dnn/outputs/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/weights&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/weights/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/outputs/weights&quot;\\n  input: &quot;dnn/outputs/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/weights/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dnn/outputs/weights&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/biases&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/biases/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dnn/outputs/biases&quot;\\n  input: &quot;dnn/outputs/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/biases/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dnn/outputs/biases&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dnn/outputs/biases&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;dnn/outputs/weights/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dnn/outputs/MatMul&quot;\\n  input: &quot;dnn/outputs/biases/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:350px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.1624895573440991&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = neuron_layer(X,n_hidden1,\"hidden1\",activation='relu')\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, 'hidden2',activation='relu')\n",
    "    logits  = neuron_layer(hidden2,n_outputs,\"outputs\")\n",
    "show_graph(tf.get_default_graph())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note in the above, we use the output of the first hidden layer into the second and so forth. `logits` is the output of the neural network **before** softmax activation. TF actually comes with many handy functions so there is no need to define your own `neuron_layer()` function as there is a built-in `fully_connected()` function that creates a fully connected layer where all the inputs are connected to all the neurons in the layer. It takes care of creating the `weights` and `biases` variables too with the proper initialization strategy, and uses the ReLU activation function by default (this can be changed with the `activation_fn` argument).\n",
    "\n",
    "Below we'll change the previous code to use the `fully_connected()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:800px;height:400px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.24963271421659594&quot;).pbtxt = 'node {\\n  name: &quot;X&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 784\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/weights/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\020\\\\003\\\\000\\\\000,\\\\001\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/weights/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.07439795136451721\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/weights/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.07439795136451721\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/weights/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden1/weights/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/weights/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden1/weights/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden1/weights/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/weights/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden1/weights/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden1/weights/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/weights/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden1/weights/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden1/weights/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/weights&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 784\\n        }\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/weights/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/weights&quot;\\n  input: &quot;hidden1/weights/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/weights/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden1/weights&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/biases/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/biases&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/biases/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/biases&quot;\\n  input: &quot;hidden1/biases/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/biases/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden1/biases&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/biases&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;hidden1/weights/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden1/MatMul&quot;\\n  input: &quot;hidden1/biases/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden1/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/weights/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;,\\\\001\\\\000\\\\000d\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/weights/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.12247448414564133\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/weights/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.12247448414564133\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/weights/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden2/weights/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/weights/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden2/weights/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden2/weights/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/weights/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden2/weights/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden2/weights/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/weights/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden2/weights/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden2/weights/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/weights&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/weights/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/weights&quot;\\n  input: &quot;hidden2/weights/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/weights/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden2/weights&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/biases/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 100\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/biases&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/biases/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/biases&quot;\\n  input: &quot;hidden2/biases/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/biases/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden2/biases&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/biases&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;hidden2/weights/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden2/MatMul&quot;\\n  input: &quot;hidden2/biases/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden2/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/weights/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;d\\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/weights/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.23354968428611755\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/weights/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.23354968428611755\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/weights/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;outputs/weights/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/weights/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;outputs/weights/Initializer/random_uniform/max&quot;\\n  input: &quot;outputs/weights/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/weights/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;outputs/weights/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;outputs/weights/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/weights/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;outputs/weights/Initializer/random_uniform/mul&quot;\\n  input: &quot;outputs/weights/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/weights&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/weights/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/weights&quot;\\n  input: &quot;outputs/weights/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/weights/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;outputs/weights&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/biases/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/biases&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/biases/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/biases&quot;\\n  input: &quot;outputs/biases/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/biases/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;outputs/biases&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/biases&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;outputs/weights/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/outputs/MatMul&quot;\\n  input: &quot;outputs/biases/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:350px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.24963271421659594&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.contrib.layers import fully_connected\n",
    "tf.reset_default_graph()\n",
    "# Placeholders for training data\n",
    "X = tf.placeholder(tf.float32, shape=(None,n_inputs),name='X')\n",
    "y = tf.placeholder(tf.int64, shape=(None),name='y')\n",
    "# Neural Network\n",
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = fully_connected(X,n_hidden1,scope= \"hidden1\")\n",
    "    hidden2 = fully_connected(hidden1, n_hidden2, scope='hidden2')\n",
    "    logits  = fully_connected(hidden2, n_outputs,scope=\"outputs\",activation_fn=None)\n",
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the neural network setup, we have to define a cost function that will be used to train it. Just like Softmax Regression we will use cross-entropy, which penalizes models that estimate low probability for the target class.\n",
    "\n",
    "TF provides functions to compute cross-entropy. Below we will use `sparse_softmax_cross_entropy_with_logits()` that computes cross entropy based on the logits (output of the network before going into softmax activation function), and it expects labels in the form of integers ranging from 0 to `n_outputs -1`. This will give a 1D tensor containing the cross entropy for each instance. We can use TF's `reduce_mean()` function to compute the mean cross entropy over all instances.\n",
    "\n",
    "> The `sparse_softmax_cross_entropy_with_logits()` function is equivalent to applying softmax activation function and then computing the cross entropy, but is more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "    loss  = tf.reduce_mean(xentropy,name='loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a neural network and now a cost function, and next we need to define a `GradientDescentOptimizer` that will tweak the model parameters to minimize the cost function. We need to define a learning rate first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize Cost Function\n",
    "eta = 0.01\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(eta)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step of the construction phase is to define how to evaluate the model. Here we will simply use accuracy as the performance measure. First for each instance, we determine if the neural network's prediction is correct by checking whether or not the highest logit corresponds to the target class. To do this we can use `in_top_k()` function which returns a 1D tensor full of boolean values, so we need to cast these booleans to floats and compute the average. This will give us the network's overall accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "with tf.name_scope('eval'):\n",
    "    # Find whether the top logit (prediction) is the same as y, returns boolean of instances\n",
    "    correct = tf.nn.in_top_k(logits,y,1) \n",
    "    # Determine accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "\n",
    "# Initialize all variables and create a SAver\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary in the construction phase we did the following:\n",
    "1. Created placeholders for the inputs and targets\n",
    "2. Created a function to build a neuron layer, and used it to create the DNN\n",
    "3. Defined the cost function\n",
    "4. Created the optimizer\n",
    "5. Defined the performance measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST data fetched by the TF function scales the data (between 0 and 1) shuffles it, and provides a simple function to load one mini-batch at a time. So we will use it instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "Train accuracy:  0.92 \t Test accuracy:  0.9\n",
      "Train accuracy:  0.96 \t Test accuracy:  0.9703\n",
      "Train accuracy:  1.0 \t Test accuracy:  0.9781\n",
      "Train accuracy:  1.0 \t Test accuracy:  0.9794\n",
      "Train accuracy:  1.0 \t Test accuracy:  0.9798\n",
      "Train accuracy:  1.0 \t Test accuracy:  0.9795\n",
      "Train accuracy:  1.0 \t Test accuracy:  0.9799\n",
      "Train accuracy:  1.0 \t Test accuracy:  0.9799\n",
      "Train accuracy:  1.0 \t Test accuracy:  0.98\n",
      "Train accuracy:  1.0 \t Test accuracy:  0.9801\n",
      "Train accuracy:  1.0 \t Test accuracy:  0.9801\n",
      "Train accuracy:  1.0 \t Test accuracy:  0.98\n",
      "Train accuracy:  1.0 \t Test accuracy:  0.9801\n",
      "Train accuracy:  1.0 \t Test accuracy:  0.9798\n",
      "Train accuracy:  1.0 \t Test accuracy:  0.98\n",
      "Train accuracy:  1.0 \t Test accuracy:  0.9799\n",
      "Train accuracy:  1.0 \t Test accuracy:  0.9799\n",
      "Train accuracy:  1.0 \t Test accuracy:  0.9802\n",
      "Train accuracy:  1.0 \t Test accuracy:  0.9799\n",
      "Train accuracy:  1.0 \t Test accuracy:  0.9798\n"
     ]
    }
   ],
   "source": [
    "# Get MNIST data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "# Epochs and batch size\n",
    "n_epochs = 40\n",
    "batch_size= 50\n",
    "\n",
    "# Train the model\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples//batch_size): #integer division\n",
    "            # Grab batch\n",
    "            X_batch,y_batch = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization\n",
    "            sess.run(training_op,feed_dict={X:X_batch,y:y_batch})\n",
    "        # Accuracy\n",
    "        acc_train = accuracy.eval(feed_dict={X:X_batch,y:y_batch})\n",
    "        acc_test  = accuracy.eval(feed_dict={X:mnist.test.images,y:mnist.test.labels})\n",
    "        if epoch % 10 == 0:\n",
    "            print(epoch,' Train accuracy: ', acc_train, '\\t Test accuracy: ', acc_test)\n",
    "    save_path=saver.save(sess,\"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above opens a TF session and runs `init` node that initializes all the variables. Then it runs the main training loop: at each epoch the code iterates through a number of mini-batches that correspond to the training set size. Each mini-batch is fetched via `next_batch()` method, and the code runs the training operation feeding it the current mini-batch input data and targets. At the end of each epoch, the code evaluates the model on the last mini-batch and the full test set. The model parameters are then saved to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Neural Network for Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the trained neural network, we can use it to make predictions. We will restore the model, use new scaled images, and evaluate the logits node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   True  Predicted\n",
       "0     7          7\n",
       "1     2          2\n",
       "2     1          1\n",
       "3     0          0\n",
       "4     4          4\n",
       "5     1          1\n",
       "6     4          4\n",
       "7     9          9\n",
       "8     5          5\n",
       "9     9          9"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'./my_model_final.ckpt')\n",
    "    X_new  = mnist.test.images[:10]\n",
    "    Z = logits.eval(feed_dict={X:X_new})\n",
    "    y_pred = np.argmax(Z,axis=1) # highest logit score is predicted class\n",
    "# Print Results\n",
    "results = pd.DataFrame(np.c_[mnist.test.labels[:10],y_pred],columns=['True','Predicted'])\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see above that the predictions are pretty good for our own neural network construction. Below we'll look at the final graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:800px;height:400px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.6687525636674888&quot;).pbtxt = 'node {\\n  name: &quot;X&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 784\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/weights/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\020\\\\003\\\\000\\\\000,\\\\001\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/weights/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.07439795136451721\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/weights/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.07439795136451721\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/weights/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden1/weights/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/weights/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden1/weights/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden1/weights/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/weights/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden1/weights/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden1/weights/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/weights/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden1/weights/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden1/weights/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/weights&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 784\\n        }\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/weights/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/weights&quot;\\n  input: &quot;hidden1/weights/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/weights/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden1/weights&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/biases/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/biases&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/biases/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/biases&quot;\\n  input: &quot;hidden1/biases/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/biases/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden1/biases&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/biases&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;hidden1/weights/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden1/MatMul&quot;\\n  input: &quot;hidden1/biases/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden1/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/weights/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;,\\\\001\\\\000\\\\000d\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/weights/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.12247448414564133\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/weights/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.12247448414564133\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/weights/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden2/weights/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/weights/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden2/weights/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden2/weights/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/weights/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden2/weights/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden2/weights/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/weights/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden2/weights/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden2/weights/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/weights&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/weights/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/weights&quot;\\n  input: &quot;hidden2/weights/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/weights/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden2/weights&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/biases/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 100\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/biases&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/biases/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/biases&quot;\\n  input: &quot;hidden2/biases/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/biases/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden2/biases&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/biases&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;hidden2/weights/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden2/MatMul&quot;\\n  input: &quot;hidden2/biases/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden2/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/weights/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;d\\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/weights/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.23354968428611755\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/weights/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.23354968428611755\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/weights/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;outputs/weights/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/weights/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;outputs/weights/Initializer/random_uniform/max&quot;\\n  input: &quot;outputs/weights/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/weights/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;outputs/weights/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;outputs/weights/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/weights/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;outputs/weights/Initializer/random_uniform/mul&quot;\\n  input: &quot;outputs/weights/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/weights&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/weights/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/weights&quot;\\n  input: &quot;outputs/weights/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/weights/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;outputs/weights&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/biases/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/biases&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/biases/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/biases&quot;\\n  input: &quot;outputs/biases/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/biases/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;outputs/biases&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/biases&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;outputs/weights/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/outputs/MatMul&quot;\\n  input: &quot;outputs/biases/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  op: &quot;SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;dnn/outputs/BiasAdd&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlabels&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/loss&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;train/gradients/Shape&quot;\\n  input: &quot;train/gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/Fill&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Reshape&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape_1&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape_2&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Prod_1&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;train/gradients/loss/loss_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Tile&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  op: &quot;PreventGradient&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;message&quot;\\n    value {\\n      s: &quot;Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\\\\\\'s interaction with tf.gradients()&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;train/gradients/loss/loss_grad/truediv&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^train/gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;outputs/weights/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden2/weights/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden1/weights/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden1/weights/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden1/weights&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden1/biases/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden1/biases&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden2/weights/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden2/weights&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden2/biases/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden2/biases&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_outputs/weights/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;outputs/weights&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_outputs/biases/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;outputs/biases&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/GradientDescent/update_hidden1/weights/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_hidden1/biases/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_hidden2/weights/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_hidden2/biases/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_outputs/weights/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_outputs/biases/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;eval/InTopK&quot;\\n  op: &quot;InTopK&quot;\\n  input: &quot;dnn/outputs/BiasAdd&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;k&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;eval/InTopK&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;eval/Cast&quot;\\n  input: &quot;eval/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^hidden1/weights/Assign&quot;\\n  input: &quot;^hidden1/biases/Assign&quot;\\n  input: &quot;^hidden2/weights/Assign&quot;\\n  input: &quot;^hidden2/biases/Assign&quot;\\n  input: &quot;^outputs/weights/Assign&quot;\\n  input: &quot;^outputs/biases/Assign&quot;\\n}\\nnode {\\n  name: &quot;save/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;hidden1/biases&quot;\\n        string_val: &quot;hidden1/weights&quot;\\n        string_val: &quot;hidden2/biases&quot;\\n        string_val: &quot;hidden2/weights&quot;\\n        string_val: &quot;outputs/biases&quot;\\n        string_val: &quot;outputs/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/SaveV2/tensor_names&quot;\\n  input: &quot;save/SaveV2/shape_and_slices&quot;\\n  input: &quot;hidden1/biases&quot;\\n  input: &quot;hidden1/weights&quot;\\n  input: &quot;hidden2/biases&quot;\\n  input: &quot;hidden2/weights&quot;\\n  input: &quot;outputs/biases&quot;\\n  input: &quot;outputs/weights&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;^save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden1/biases&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2/tensor_names&quot;\\n  input: &quot;save/RestoreV2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/biases&quot;\\n  input: &quot;save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden1/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_1/tensor_names&quot;\\n  input: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/weights&quot;\\n  input: &quot;save/RestoreV2_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden2/biases&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_2/tensor_names&quot;\\n  input: &quot;save/RestoreV2_2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_2&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/biases&quot;\\n  input: &quot;save/RestoreV2_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden2/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_3/tensor_names&quot;\\n  input: &quot;save/RestoreV2_3/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_3&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/weights&quot;\\n  input: &quot;save/RestoreV2_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;outputs/biases&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_4/tensor_names&quot;\\n  input: &quot;save/RestoreV2_4/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_4&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/biases&quot;\\n  input: &quot;save/RestoreV2_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/biases&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;outputs/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_5/tensor_names&quot;\\n  input: &quot;save/RestoreV2_5/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_5&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/weights&quot;\\n  input: &quot;save/RestoreV2_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^save/Assign&quot;\\n  input: &quot;^save/Assign_1&quot;\\n  input: &quot;^save/Assign_2&quot;\\n  input: &quot;^save/Assign_3&quot;\\n  input: &quot;^save/Assign_4&quot;\\n  input: &quot;^save/Assign_5&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:350px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.6687525636674888&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fine-Tuning Neural Network Hyperparameters <a class=\"anchor\" id=\"hyperparameters\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many hyperparameters to tweak in neural networks, which could be seen as their biggest drawback. For example in a simple MLP you can change the number of layers, the number of neurons per layer, type of activation function, the weight initialization logic, and much more. \n",
    "\n",
    "We could use grid search with cross-validation to find the right hyperparameters, but there are so many hyperparameters to tune, and since training a neural network on a large dataset takes a lot of time you would only be able to explore a small part of the hyperparameter space in a reasonable time. You could use a random grid search which would be better. It is good to know what values are reasonable for each hyperparameter so you can restrict the search space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Hidden Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can always start with a single hidden layer and you will get reasonable results, as MLP with one hidden layer can do a good job with sufficient number of neurons. The advantage of more layers is that fewer neurons are needed than shallow nets making them faster to train. The reason for this is that lower hidden layers model low-level structures (e.g. line segments), intermediate hidden layers combine the low-level structures to model intermediate-level structures (e.g. squares) and the highest hidden layers and the output layer combine these intermediate structures to model high-level structures (e.g. faces). The hierarchial architecture helps DNNs converge faster to solution and improves their ability to generalize to new datasets. \n",
    "\n",
    "In summary you can start with one or two hidden layers and it will work well (you can get over 97 and 98% on MNIST with 1 and 2 layers with the same number of neurons). For more complex problems, you can ramp up the number of hidden layers until you start overfitting the training set. Very complex tasks require dozens of hidden layers (though not all connected) and need a huge amoutn of training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Neurons per Hidden Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of neurons in the input and output layers is determined by the type of input and output the task requires. For example, MNIST requires 28x28=784 input neurons and 10 output neurons. Like for the hidden layers, a common practice is to size them to form a funnel with fewer and fewer neurons at each layer - many low-level features coalesce into fewer high-level features. This practice however is not as common now, as you could choose the same size for all hidden layers. \n",
    "\n",
    "In general you will see better model improvement by increasing the number of layers than the number of neurons per layer. But finding the perfect number of neurons is not an exact science expect for trial and error. One approach is to pick a model with more layers and more neurons than needed, and use early stopping to prevent it from overfitting (the *dropout* technique is common)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most cases the ReLU activation function can be used in the hidden layers. It is a bit faster to compute than other activation functions, and Gradient Descent does not get stuck as much on plateaus thanks to the fact that it does not saturate for large input values (unlike the logistic or hyperbolic tangent function). For the output layer, the softmax activation function is generally a good choice for classification tasks (when the classes are mutually exclusive). For **regression** tasks you can simply use no activation function at all.\n",
    "\n",
    "For handling the output layer, if the problem is binary classification, logistic activation function can be used when estimating the probability. If the problem is multiclass, then you must replace the logistic function with the softmax activation function which can handle multiple classes. If you wanted to predict housing prices, then you would need no activation function at all in the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Revised Calling Methods <a class=\"anchor\" id=\"new\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although above we used `tf.contrib.layers.fully_connected()` for our neural networks, it is now preferable to use `tf.layers.dense()`. They are almost identical except for a couple differences:\n",
    "\n",
    "* Parameters are renamed, `scope` is `name`, `activation_fn` is `activation`, `weights_initializer` is `kernel_initializer`\n",
    "* The default `activation` is now `None` instead of `relu`\n",
    "\n",
    "We will repeat the DNN example with the new methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Train accuracy:  0.9 \t Test accuracy:  0.8986\n",
      "10  Train accuracy:  0.98 \t Test accuracy:  0.9586\n",
      "20  Train accuracy:  0.98 \t Test accuracy:  0.9706\n",
      "30  Train accuracy:  0.98 \t Test accuracy:  0.9769\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:800px;height:400px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.5328070968827491&quot;).pbtxt = 'node {\\n  name: &quot;X&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 784\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\020\\\\003\\\\000\\\\000,\\\\001\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.07439795136451721\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.07439795136451721\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 784\\n        }\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;hidden1/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden1/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;hidden1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden1/MatMul&quot;\\n  input: &quot;hidden1/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden1/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;,\\\\001\\\\000\\\\000d\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.12247448414564133\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.12247448414564133\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 100\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;hidden2/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden2/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;hidden2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden2/MatMul&quot;\\n  input: &quot;hidden2/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden2/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;d\\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.23354968428611755\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.23354968428611755\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 100\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;outputs/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;outputs/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;outputs/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;outputs/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/outputs/MatMul&quot;\\n  input: &quot;outputs/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  op: &quot;SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;dnn/outputs/BiasAdd&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlabels&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/loss&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;train/gradients/Shape&quot;\\n  input: &quot;train/gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train/gradients/Fill&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Reshape&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape_1&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Shape_2&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Prod_1&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Prod&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;train/gradients/loss/loss_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/loss_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Tile&quot;\\n  input: &quot;train/gradients/loss/loss_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  op: &quot;PreventGradient&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;message&quot;\\n    value {\\n      s: &quot;Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\\\\\\'s interaction with tf.gradients()&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;train/gradients/loss/loss_grad/truediv&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^train/gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;outputs/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train/gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden1/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden1/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden2/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_hidden2/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_outputs/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent/update_outputs/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;train/GradientDescent/learning_rate&quot;\\n  input: &quot;train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train/GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train/GradientDescent/update_hidden1/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_hidden1/bias/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_hidden2/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_hidden2/bias/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_outputs/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^train/GradientDescent/update_outputs/bias/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;eval/InTopK&quot;\\n  op: &quot;InTopK&quot;\\n  input: &quot;dnn/outputs/BiasAdd&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;k&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;eval/InTopK&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;eval/Cast&quot;\\n  input: &quot;eval/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^hidden1/kernel/Assign&quot;\\n  input: &quot;^hidden1/bias/Assign&quot;\\n  input: &quot;^hidden2/kernel/Assign&quot;\\n  input: &quot;^hidden2/bias/Assign&quot;\\n  input: &quot;^outputs/kernel/Assign&quot;\\n  input: &quot;^outputs/bias/Assign&quot;\\n}\\nnode {\\n  name: &quot;save/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;hidden1/bias&quot;\\n        string_val: &quot;hidden1/kernel&quot;\\n        string_val: &quot;hidden2/bias&quot;\\n        string_val: &quot;hidden2/kernel&quot;\\n        string_val: &quot;outputs/bias&quot;\\n        string_val: &quot;outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/SaveV2/tensor_names&quot;\\n  input: &quot;save/SaveV2/shape_and_slices&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;outputs/kernel&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;^save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2/tensor_names&quot;\\n  input: &quot;save/RestoreV2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_1/tensor_names&quot;\\n  input: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;save/RestoreV2_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_2/tensor_names&quot;\\n  input: &quot;save/RestoreV2_2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_2&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;save/RestoreV2_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_3/tensor_names&quot;\\n  input: &quot;save/RestoreV2_3/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_3&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;save/RestoreV2_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;outputs/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_4/tensor_names&quot;\\n  input: &quot;save/RestoreV2_4/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_4&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;save/RestoreV2_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_5/tensor_names&quot;\\n  input: &quot;save/RestoreV2_5/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_5&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;save/RestoreV2_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^save/Assign&quot;\\n  input: &quot;^save/Assign_1&quot;\\n  input: &quot;^save/Assign_2&quot;\\n  input: &quot;^save/Assign_3&quot;\\n  input: &quot;^save/Assign_4&quot;\\n  input: &quot;^save/Assign_5&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:350px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.5328070968827491&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Construction\n",
    "tf.reset_default_graph()\n",
    "\n",
    "n_inputs = 28*28 # number of pixels\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "# Placeholders for training data\n",
    "X = tf.placeholder(tf.float32, shape=(None,n_inputs),name='X')\n",
    "y = tf.placeholder(tf.int64, shape=(None),name='y')\n",
    "# Neural Network\n",
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = tf.layers.dense(X,n_hidden1,name= \"hidden1\",activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name='hidden2',activation=tf.nn.relu)\n",
    "    logits  = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "# Loss Function\n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "    loss  = tf.reduce_mean(xentropy,name='loss')\n",
    "# Minimize Cost Function\n",
    "eta = 0.01\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(eta)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "# Evaluation\n",
    "with tf.name_scope('eval'):\n",
    "    # Find whether the top logit (prediction) is the same as y, returns boolean of instances\n",
    "    correct = tf.nn.in_top_k(logits,y,1) \n",
    "    # Determine accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "# Initialize all variables and create a SAver\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Execution\n",
    "# Epochs and batch size\n",
    "n_epochs = 40\n",
    "batch_size= 50\n",
    "# Train the model\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples//batch_size): #integer division\n",
    "            # Grab batch\n",
    "            X_batch,y_batch = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization\n",
    "            sess.run(training_op,feed_dict={X:X_batch,y:y_batch})\n",
    "        # Accuracy\n",
    "        acc_train = accuracy.eval(feed_dict={X:X_batch,y:y_batch})\n",
    "        acc_test  = accuracy.eval(feed_dict={X:mnist.test.images,y:mnist.test.labels})\n",
    "        if epoch % 10 == 0:\n",
    "            print(epoch,' Train accuracy: ', acc_train, '\\t Test accuracy: ', acc_test)\n",
    "    save_path=saver.save(sess,\"./my_model_final.ckpt\")\n",
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The material in this notebook is made available under the [Creative Commons Attribution license](https://creativecommons.org/licenses/by-nc/4.0/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
