{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Deep Neural Networks <a class=\"anchor\" id=\"top\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was written by following the textbook of  Aurélien Géron's *Hands-On Machine Learning with Scikit-Learn and TensorFlow*, along with associated datasets ([Link to Github Repo](https://github.com/ageron/handson-ml/)). The contents in this notebook are my notes from reading the textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook by Justin Bandoro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For complex problems, such as detecting hundreds of types of objects in high-resolution images, you may need to train a deeper DNN with up to 10 layers, each containing hundreds of neurons, connected by hundred of thousands of connections. There are a few problems that arise:\n",
    "\n",
    "1. *Vanishing gradient* problem (or exploding gradient) that affects deep neural networks and makes lower layers hard to train.\n",
    "2. Training would be quite slow with such a large network.\n",
    "3. A model with millions of parameters would risk overfitting the training set.\n",
    "\n",
    "We will address all of the above with techniques to solve them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.io as sio\n",
    "from matplotlib import cm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing TensorBoard in Jupyter\n",
    "Quick script to view our graphs in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = b\"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:350px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:800px;height:400px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vanishing/Exploding Gradients Problem <a class=\"anchor\" id=\"vanishing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The backpropagation method works by going from the output layer to the input layer, propagating the error gradient on the way. When the algorithm  has computed the gradient of the cost function with regards to each parameter in the network, it uses the gradients to update each parameter with a Gradient Descent step.\n",
    "\n",
    "As the algorithm proceeds backwards down all of the layers, the gradients get smaller and smaller. As a result, the updating of lower layers can leave the connection weights virtually unchanged, and training never converges to a good solution. This is called **vanishing gradients** problem, and in some cases the opposite can happen: the gradients can grow larger and larger and layers get insanely large weight updates and the algorithm diverges (**exploding gradients**). The latter is encountered in recurrent neural networks. This was one of the reasons that DNNs were abandonned in the 1990s.\n",
    "\n",
    "It was found in 2010 that the combination of the popular logistic sigmoid activation function and the weight initialization technique of a normal distribution with a mean of 0 and standard deviation of 1. It was found that the variance of outputs of each layer was greater than the variance of its inputs, and thus going forward the the variance keeps increasing after each layer until the activation function saturates at the top layers. Looking at the logistic activation function below we see that when the inputs become large (negative or positive) the function satures at 0 or 1 with a derivative close to 0. Thus when backpropagtion kicks in there is virtually no gradient to propagate back through the network. The gradient that is propagated backwards is diluted after each layer and there is nothing left in the lower layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x12be1d668>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAADTCAYAAACYyoqOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl8VPW9//HXJ/tGQhb2hEUgIKIi\nRCjaVqrQQoulty5Qr1ZaW1xqe7lqW7UurXprr9Vb7K9uaJUqrUihWkQUi1XrgkpARIMGwpoQloSE\n7Nsk398fiTRAIAEyOTOT9/PxmMfMmfPNzJshD96cM+d8jznnEBERkeAX5nUAERER6RwqdRERkRCh\nUhcREQkRKnUREZEQoVIXEREJESp1ERGREKFSFxERCREqdRERkRChUhcREQkREV4HOF5paWlu8ODB\nXscQ6VZyc3MBGDFihMdJRLqftWvXFjvnenVkbNCV+uDBg8nOzvY6hki3MmnSJADeeOMNT3OIdEdm\ntqOjY7X7XUREJET4rdTN7Ekz22dmnxxlvZnZ780sz8w2mNlYf2URERHpDvy5+30B8Afg6aOsnwYM\nb7lNAB5puReRAKPd7iLBwW9b6s65fwElxxgyA3jaNXsP6Glm/fyVR0REJNR5eaDcACC/1XJBy3O7\nDx9oZnOAOQADBw7sknAi8m/3338/ADfddJPHSUQ6n3OOOl8TtQ2NVNc3UtvQeHC5rfs6XxP1rW+N\nja0eNxEZHsZdM0Z78mfxstStjedcWwOdc/OB+QBZWVltjhER/1m+fDmgUpfA8HkJl9c2UF7jo7y2\ngYpaH+U1DVTW+aiq81FV10hVvY/KOh/VdT4q6xqpqvNRXe+jpqGx+VbfcmtopOkkmiU8zIgKDyMq\novmWEhfVeX/Y4+RlqRcAGa2W04FCj7KIiIgHGpscpdX1FFfWsb+yntLqekqrGzhQVc+BmgZKq+s5\nUN18X1bdQFlNc4HXNza1+9rREWEkREcQHx1BXFQ4CdERJMVF0S8ynLiocGKiwomLDCc2quUW2XyL\niQwnJjKM6IhwolvuDy5HhDU/Fx5+sMTDw9raRvWGl6W+DLjezBbRfIBcmXPuiF3vIiISfBoam9hX\nUceeshp2l9Wyp6yWveW1FFc2F3hRRR3FlfWUVNUddSs5PiqcnnFR9IyLJDkuigE9Y0mKjaRHTCSJ\nsRHN9zERJLZa/rzE46PCiQjvfmdt+63UzexZYBKQZmYFwJ1AJIBz7lFgBfB1IA+oBr7nrywiItK5\nqup85JdWk19Sw86SavJLqik8UMOe8lp2l9VSXFmHO6ysoyPCSEuIJq1HNOnJsYzJ6Nm8nBBFWo9o\nUuOjSYmPIjkukqS4SKIjwr35wwUxv5W6c+477ax3wI/89f4i0nliY2O9jiAeqKrzsbWoiryiCrbs\nq2JnSTU7S6opKK2muLL+kLEJ0RH07xlD36RYTu2bSN+kGPolxdCn5b5fYiyJsRGYBc6u6lAUdNPE\nikjXe/nll72OIH50oLqez/ZUkLevkrx9lWwpqmTLvkoKy2oPjgkPM/r3jGFgShxTRvUhPTmOgSnN\nt4yUOJLjIlXYAUClLiLSTTjn2F1WS05hOTmFZeQUlrOxsJxdB2oOjomLCmdorwQmnJLK0F7xDOud\nwNBeCQxKjScqovt9Rx1sVOoi0q67774bgNtvv93jJHI8SqvqWbezlOwdpWwoOMDGwnJKqxsAMIMh\nafGMHZTMFRMHcWq/RIb3TqBfUoy2uIOYSl1E2vXaa68BKvVA1tTk2Fpcydodpazd0VzkW4uqAIgI\nM07tl8jXTuvLaf0TGdU/iZF9exAfrQoINfobFREJQs45thRV8fbmIt7OKyZ7RykHWrbCk+MiGTco\nmYvHpTNuYDJnZvQkJlJHkncHKnURkSBRUlXP23nFzUW+ufjggWyDU+OYelpfxg5KZtygZE5Ji9cu\n9G5KpS4iEqCamhzrCw7wj417eWtzETmF5TgHiTERfHF4GtcP68WXhqeRkRLndVQJECp1EWlXamqq\n1xG6DV9jEx9sL2HlJ3tYmbOXPeW1RIQZYwclc8PkTL6U2YvTByQF1NSkEjhU6iLSrqVLl3odIaTV\n+Rp5J6+YVz7Zwz827qW0uoGYyDDOy+zFzaNH8pWRvUmKjfQ6pgQBlbqIiAeamhwfbC/hr9kFrMzZ\nQ2Wdjx7REVxwam+mju7LlzN7ERelf6Ll+Og3RkTadcsttwBw7733epwk+OWXVPO3dbtYsi6f/JIa\nEqIjmDa6L18/ox/nDE3VfOdyUlTqItKu1atXex0hqNXUN/JKzm7+ml3Au1v2A3DO0FRumJLJ107r\nqy1y6TT6TRIR8ZO8fRU8+c52lq0vpLLOR0ZKLP89OZOLxg0gPVlHrEvnU6mLiHQi5xz/2lzMH9/e\nxr82FREVEcaFZ/Tnkqx0xg9OIUxHrYsfqdRFRDpBTX0jz3+4iyff2Ubevkp69YjmximZXDZhIKkJ\n0V7Hk25CpS4i7UpPT/c6QsDaW17L06u385f3d1Ja3cBp/RP5v0vPZPoZ/XVVM+lyKnURadfChQu9\njhBwdpfV8PDrW1i0Zie+JsdXR/Xh++cOYfyQFE3RKp5RqYuIHIe95bU88sYW/vL+ThyOS7IyuObL\nQxmYqgPfxHsqdRFp19y5cwGYN2+ex0m8s6+ilkff2Mqf399BY5Pj4nHp/OgrwzTvugQUlbqItGv9\n+vVeR/BMcWUdj725hWfe20FDo+PbZw3gx+cP15a5BCSVuohIG2rqG3nsX1t47M2t1Pka+dZZA/jJ\n+cMZnBbvdTSRo/JrqZvZVOBBIBx4wjn3m8PWDwT+BPRsGXOzc26FPzOJiByLc47lG3Zz74pPKSyr\n5Run9+OGr2YytFeC19FE2uW3UjezcOAhYApQAKwxs2XOuY2tht0GLHbOPWJmo4AVwGB/ZRIROZaP\nC8q4a3kOa7aXclr/RObNOovxQ1K8jiXSYf7cUh8P5DnntgKY2SJgBtC61B2Q2PI4CSj0Yx4ROUGZ\nmZleR/Crooo67l+Zy+K1+aTERfGbb5/OJVkZuma5BB1/lvoAIL/VcgEw4bAxvwReNbMfA/HA5LZe\nyMzmAHMABg4c2OlBReTY5s+f73UEv6j3NbHg3W38/rU8ahsa+cEXh/DjC4aTGKNrl0tw8mept/Vf\nXHfY8neABc65B8xsIvCMmY12zjUd8kPOzQfmA2RlZR3+GiIix23tjlJ+vnQDefsqOX9kb37xjVP1\nvbkEPX+WegGQ0Wo5nSN3r18FTAVwzq02sxggDdjnx1wicpzmzJkDhMYWe3W9j9+uzGXBu9vpnxTL\nU7PP5isje3sdS6RT+LPU1wDDzWwIsAuYBVx22JidwAXAAjM7FYgBivyYSUROwKZNm7yO0Cne3lzM\nzX/bQEFpDd+dOIifTR1JQrTO7JXQ4bffZuecz8yuB1bSfLrak865HDO7C8h2zi0DbgQeN7P/pnnX\n/GznnHavi0inKqtp4H9e2sji7AKGpMWz+OqJOqpdQpJf/4vacs75isOeu6PV443Auf7MICLd28qc\nPdz+wifsr6rn2klD+a8LhhMTGe51LBG/0H4nEQlJZdUN3Pb3T3jxo0JO7ZfIH688m9PTk7yOJeJX\nKnURadeYMWO8jnBcPthWwtxFH7Kvoo4bp2RyzaShRIbr2uYS+lTqItKuYLk6m6+xid//M48//HMz\nA1PiWHrtOZyZ0dPrWCJdRqUuIiEhv6Sauc+tZ+2OUi4am86vZpymI9ul29FvvIi06/LLLwdg4cKF\nHidp24sfFXLr8x+DgwdnjWHGmAFeRxLxhEpdRNpVUFDgdYQ2VdX5uHNZDkvWFjB2YE8enHUWGSm6\nzrl0Xyp1EQlKn+4u57o/r2PH/ip+cv4wfnLBcCJ0MJx0cyp1EQk6L3y4i5v/toGk2Eie/eEXmHBK\nqteRRAKCSl1EgkZDYxP/89KnLHh3O+OHpPDQZWPp1SPa61giAUOlLiLtmjhxotcR2Fdey4/+so41\n20u56otDuHnaSJ17LnIYlbqItOvee+/19P3X7ijh2oXrqKj16eh2kWNQqYtIwHLO8fTqHdy9fCPp\nybE8fdV4RvZN9DqWSMBSqYtIuy666CIAli5d2mXvWVPfyC+e/5i/fbiLC0b25v9mjiEpNrLL3l8k\nGKnURaRd+/fv79L321deyw+ezubjXWXcMCWT678yjLAw69IMIsFIpS4iAeWTXWX88OlsymoamH9F\nFlNG9fE6kkjQUKmLSMBYmbOHuYvWkxwXyZJrzmFUf31/LnI8VOoi4jnnHPP/tZXfvPIZZwxI4vHv\nZtE7McbrWCJBR6UuIu264IIL/Pba9b4mbnvhYxZnF/CN0/vxwKVnEhMZ7rf3EwllKnURadftt9/u\nl9ctrarnmoVreX9bCT85fxhzJ2fqgDiRk6BSFxFPbCmq5KoFayg8UMu8mWP41lmaUEbkZKnURaRd\n06ZNA+Dll1/ulNfL3l7CVX/KJiLM+MsPJ5A1OKVTXleku/PrxMlmNtXMcs0sz8xuPsqYS81so5nl\nmNlf/JlHRE5MTU0NNTU1nfJar3yyh/984n1S4qN4/rpzVeginchvW+pmFg48BEwBCoA1ZrbMObex\n1ZjhwC3Auc65UjPr7a88IuK9P727nV++mMOZ6T15cvbZpMRHeR1JJKT4c/f7eCDPObcVwMwWATOA\nja3G/BB4yDlXCuCc2+fHPCLikaYmx/+u/IzH3tzK5FP78P++cxaxUTrCXaSz+XP3+wAgv9VyQctz\nrWUCmWb2jpm9Z2ZT23ohM5tjZtlmll1UVOSnuCLiD/W+Jm5YvJ7H3tzKf04YyKOXj1Whi/iJP7fU\n2zovxbXx/sOBSUA68JaZjXbOHTjkh5ybD8wHyMrKOvw1RMTPpk+ffkI/V17bwLUL1/JO3n5++rUR\nXDdpKGY6ZU3EX/xZ6gVARqvldKCwjTHvOecagG1mlktzya/xYy4ROU433XTTcf/M3vJarnzyA/L2\nVfLAJWdy0bh0PyQTkdb8uft9DTDczIaYWRQwC1h22JgXgK8AmFkazbvjt/oxk4h0gbx9lXz74XfJ\nL6nmydlnq9BFuojfttSdcz4zux5YCYQDTzrncszsLiDbObesZd1XzWwj0Aj81DnXtdd4FJF2TZo0\nCYA33nij3bHr8w/wvac+IDwsjOeunsjoAUn+DSciB/l18hnn3ApgxWHP3dHqsQNuaLmJSJB7a3MR\nVz+zltSEKBZeNYFBqfFeRxLpVjSjnIh0iuUbCvnv59YztFcCT39/vK6yJuIBlbqInLRnVm/njmU5\nnD0ohcevzCIpNtLrSCLdkkpdRE6Yc455qzbz4GubmXxqb/5w2VhdNlXEQyp1EWnXpZdeesRzjU2O\nXy7L4Zn3dnDxuHR+8+3TiQj36+UkRKQdKnURadd11113yHKdr5EbFn/ESxt2c/WXT+HmaSM1qYxI\nAFCpi0i7qqurAYiLi6Oqzsc1C9fy1uZibpk2kqvPG+pxOhH5nEpdRNr19a9/HYDnX3qV7y1Yw4aC\nA9x38RlcmpXRzk+KSFdSqYtIh9T7mrj0sdXsKKnmkcvH8bXT+nodSUQOY83zvxxjgNmdzrlfdVGe\ndvXo0cONGzfukOcuvfRSrrvuOqqrqw9uUbQ2e/ZsZs+eTXFxMRdffPER66+99lpmzpxJfn4+V1xx\nxRHrb7zxRi688EJyc3O5+uqrj1h/2223MXnyZNavX8/cuXOPWP/rX/+ac845h3fffZdbb731iPXz\n5s1jzJgxrFq1invuueeI9Y899hgjRozgxRdf5IEHHjhi/TPPPENGRgbPPfccjzzyyBHrlyxZQlpa\nGgsWLGDBggVHrF+xYgVxcXE8/PDDLF68+Ij1n88idv/997N8+fJD1sXGxvLyyy8DcPfdd/Paa68d\nsj41NZWlS5cCcMstt7B69epD1qenp7Nw4UIA5s6dy/r16w9Zn5mZyfz58wGYM2cOmzZtOmT9mDFj\nmDdvHgCXX345BQUFh6yfOHEi9957LwAXXXQR+/cfOmHhBRdcwO233w7AtGnTqKmpOWT99OnTD857\n/vmsaq11l9+9EaeOYsv2nUT3OYURfXqQ2HLKmn739Lunf/f8/7v3+OOPr3XOZR0Rsg0d2VK/08zi\ngBRgHbDo8+ufi0joyyksY2dJDc7BqH6JxEdrB59IoOrIlnojcA/wMTAW+A9glnPuI//HO1JWVpbL\nzs724q1Fup0PtpVw1YI17HzmZ4zsl8j777zldSSRbsfMOnVL/TPn3J0tj5eY2QLgUeD8E8wnIkHg\nn5/t5dqF6xiQHMv3b/oRyXFRXkcSkXZ0pNSLzWycc24tgHNuk5n18nMuEfHQCx/u4qa/fsSo/ok8\nNftsUhMmeR1JRDqgI6X+E2CRma2leRf8GcA2v6YSEc88+fY27lq+kYmnpPL4lVkkREdQXFwMQFpa\nmsfpRORY2i1159xHZjYGmAyMBl4HnvV3MBHpWs457n81l4de38K00X353cwxB+dx//zo6Y5cT11E\nvNOhw1idc3XASy03EQkxjU2O2174mGc/yOc74wdyz7dGEx6maV9Fgo3OTRHp5mobGpm7aD2v5Ozh\nx+cP44YpmZrHXSRIqdRFurGK2gZ++HQ2720t4c4LR/G9c4d4HUlEToJKXaSbKqqoY/ZTH5C7p4J5\nM8fwrbMGeB1JRE6SSl2kG8ovqeaKP77P3vI6nrgyi0kjeh9z/LXXXttFyUTkZKjURbqZnMIyZj+1\nhnpfEwt/MIFxg5Lb/ZmZM2d2QTIROVlh/nxxM5tqZrlmlmdmNx9j3MVm5sysQ9PgiciJeWtzEZc+\nuprIMGPJNRM7VOgA+fn55Ofn+zmdiJwsv22pm1k48BAwBSgA1pjZMufcxsPG9aB5gpv3/ZVFROBv\n6wr42ZINDOudwILvjadvUkyHf/bzq3jpPHWRwObPLfXxQJ5zbqtzrh5YBMxoY9zdwH1ArR+ziHRb\nzjkeej2PGxZ/xPghKSy+ZuJxFbqIBA9/lvoAoPX+uoKW5w4ys7OADOfcoRerPYyZzTGzbDPLLioq\n6vykIiGqsclx+98/4bcrc5kxpj8LvjeexJhIr2OJiJ/480C5tmavOHidVzMLA34HzG7vhZxz84H5\n0Hzp1U7KJxLSauob+cmiD/nHxr1cfd4p/PxrIwnTLHEiIc2fpV4AZLRaTgcKWy33oHku+TdaZq/q\nCywzs28653TBdJGTUFJVz1V/WsP6/AP88sJRzNakMiLdgj9LfQ0w3MyGALuAWcBln690zpUBBy/5\nZGZvADep0EVOzvbiKr6/YA0FB2p4+LKxTDu930m/5o033tgJyUTE3/xW6s45n5ldD6wEwoEnnXM5\nZnYXkO2cW+av9xbprt7bup9rFq4F4M8/mMDZg1M65XUvvPDCTnkdEfEvv04+45xbAaw47Lk7jjJ2\nkj+ziIS6xdn5/OL5j8lIiePJK89mcFp8p712bm4uACNGjOi01xSRzqcZ5USCXFOT476VuTz65hbO\nHZbKw5eNIymuc49wv/rqqwGdpy4S6FTqIkGsut7H3EXreXXjXi6bMJBfffM0IsP9OlGkiAQwlbpI\nkNpTVstVf1rDp7vLuWP6KL537mBdB12km1OpiwShjwvK+MHTa6is9fHElVmcP7KP15FEJACo1EWC\nzPINhdz0149IjY9m6XXnMLJvoteRRCRAqNRFgoSvsYn7VuYy/19bGTuwJ49dkUWvHtFd8t633XZb\nl7yPiJwclbpIECiurOPHf/mQ1Vv3892Jg7jtG6OIiui6A+ImT57cZe8lIidOpS4S4D7cWcp1f15H\nSVU9D1xyJheNS+/yDOvXrwdgzJgxXf7eItJxKnWRAPbsBzu58+859E6MZum15zB6QJInOebOnQvo\nPHWRQKdSFwlAtQ2N3Pn3HJ7LzufLmb34/awx9IyL8jqWiAQ4lbpIgNl1oIZrF65lQ0EZPz5/GHMn\nZxKuS6aKSAeo1EUCyCuf7ObnSz+mqcnx+HezmDJK55+LSMep1EUCQE19I3ct38izH+zkjPQkfj/r\nrE69IIuIdA8qdRGPbSws58fPrmNrcRXXnDeUG6Zkdunpah3x61//2usIItIBKnURjzjneOqd7fzm\n5c/oGRfJwqsmcO6wNK9jtemcc87xOoKIdIBKXcQDRRV1/HTJR7yRW8TkU3tz38VnkhIfuEe3v/vu\nu4DKXSTQqdRFutibm4q4cfFHlNc2cNeM07jiC4MC/upqt956K6Dz1EUCnUpdpIuU1TTw65c+5bns\nfDL7JPDnH0xgRN8eXscSkRCiUhfpAq/m7OG2Fz5hf1U915w3lLmThxMTGe51LBEJMSp1ET8qrqzj\nl8tyWL5hN6f2S+SPV57N6eneTPUqIqFPpS7iB845Xli/i1+9uJHqukZu+momV583lMjwwDpVTURC\ni19L3cymAg8C4cATzrnfHLb+BuAHgA8oAr7vnNvhz0wi/lZ4oIZfPP8xr+cWcdbAntx30RkM7xPc\n353PmzfP6wgi0gF+K3UzCwceAqYABcAaM1vmnNvYatiHQJZzrtrMrgXuA2b6K5OIP9X7mnh69Xbm\nrdpMY5PjjumjuPKcwSExb7suuSoSHPy5pT4eyHPObQUws0XADOBgqTvnXm81/j3gcj/mEfEL5xyv\n5+7jnuWfsrW4ikkjenH3jNFkpMR5Ha3TrFq1CoDJkyd7nEREjsWfpT4AyG+1XABMOMb4q4CX21ph\nZnOAOQADBw7srHwiJy1vXwV3L/+UNzcVcUqveJ6afTZfGdnb61id7p577gFU6iKBzp+l3tY+R9fm\nQLPLgSzgvLbWO+fmA/MBsrKy2nwNka5UVt3AvNc28czqHcRGhXP79FF8d+IgHQgnIp7yZ6kXABmt\nltOBwsMHmdlk4BfAec65Oj/mETlpjU2OZz/YyQOv5nKgpoHvjB/IjVMySU2I9jqaiIhfS30NMNzM\nhgC7gFnAZa0HmNlZwGPAVOfcPj9mETkpjU2Olz7ezYOrNrGlqIoJQ1K448JRnNZf55yLSODwW6k7\n53xmdj2wkuZT2p50zuWY2V1AtnNuGfBbIAH4a8vc1zudc9/0VyaR49XU5Hj5kz3MW7WJzfsqyeyT\nwKOXj+Vrp/UN+PnaRaT7MeeC6yvqrKwsl52d7XUMCXHOOVbm7GXeqk18tqeCob3imTs5k2+c3o+w\nEDhF7Xjl5uYCMGLECI+TiHQ/ZrbWOZfVkbGaUU6kFeccqz7dx+/+sYmNu8s5JS2eB2eNYfoZ/UPi\nfPMTpTIXCQ4qdRGaJ45ZvqGQP769jZzCcgalxvHAJWcyY0x/InREOy+++CIAF154ocdJRORYVOrS\nre2vrOMv7+/k6fd2UFRRx9Be8dx30Rn8x9gBOj2tlQceeABQqYsEOpW6dEu5eyp46p1tPP/hLup8\nTXw5sxf3XzKELw1L65bfmYtIaFCpS7fR2OR4c9M+nnpnO29tLiY6Ioxvj03n++cODvoLroiIgEpd\nuoGtRZUsWVvA39btYk95LX0So/np10Zw2fiBJMdHeR1PRKTTqNQlJFXUNvDSht38dW0Ba3eUEmZw\nXmYvbp8+iimj+hAVoe/LRST0qNQlZDQ2Od7bup8lawt4+ZPd1DY0MbRXPDdPG8m3zxpA78QYryMG\nrWeeecbrCCLSASp1CWoNjU2s3rKfV3L28GrOXoor6+gRE8G3x6Zzybh0xmT01MxvnSAjI6P9QSLi\nOZW6BJ3ahkb+tamIV3L2sGrjXsprfcRFhfOVEb2ZOrovU0b1ISYy3OuYIeW5554DYObMmR4nEZFj\nUalLUNhXUcvbm4tZ9ele3sgtorq+kaTYSKaM6svU0X350vA0FbkfPfLII4BKXSTQqdQlINXUN/LB\n9hLe3lzEW5uL+WxPBQBpCdH8x1kDmDa6HxNOSdEEMSIirajUJSD4Gpv4dHcF72wp5q3NRazZXkq9\nr4mo8DDOHpLMz6eO5EvD0xjVL1GTw4iIHIVKXTxRVtPAup2lrNtRytodpazPP0B1fSMAI/v24MqJ\ng/ji8F6MH5xCbJR2q4uIdIRKXfyuobGJLUWVfFxQxrqdzSW+aW8lAOFhxqh+iVyalcHYQcl8YUiK\nTj0TETlBKnXpVNX1Pj7dXcHGwjJyCsvJKSwnd28F9b4mABJjIhg7KJlvntmfsYOSOTO9J/HR+jUM\ndEuWLPE6goh0gP41lRNSXe9ja1EVW4oqydtXyZaiSj7bU8G24iqcax7TMy6S0/onMvucwYzql8jo\nAYmckpag78SDUFpamtcRRKQDVOpyVPW+JnYdqGFnSTU7S6rZVlRFXlElW/ZVsutAzcFxYQaDUuMZ\n1juBb57Zn9P6JzGqfyL9k2I08UuIWLBgAQCzZ8/2NIeIHJtKvRurbWhkT1ktu8tq2V1WQ0Hpvwu8\noKSa3eW1B7e6AWIjwxnaO56swcnM6pXB0N4JDOudwKDUOKIjdDBbKFOpiwQHlXoIqqlvpLiyjqLK\nOoor6thfVU9RRR27y2rZU1bD7rJa9pbXUlrdcMTP9kmMZmBKHF8YmkpGchwDU+IYmBpHRnIcvXtE\na9e5iEgAU6kHMOccNQ2NVNT6KK2u50B1Aweq6ymtbji4XFr17+XilhKvajk17HBpCVH0TYohPTmW\nrMHJ9EuKpW9iDP2SYuiTFMOAnrGalU1EJIj5tdTNbCrwIBAOPOGc+81h66OBp4FxwH5gpnNuuz8z\n+VtjU3MRV9f7qK1vorrBR3V9I1V1vpZbI1X1PipbLVfW+aiobaCi1kf55/c1zfe+JnfU94qOCCM5\nLoqecZGkxEdxZnpP0hKiSesRRVp8y31CNGkJ0aQmRGkXuYhIiPNbqZtZOPAQMAUoANaY2TLn3MZW\nw64CSp1zw8xsFvC/QJdNLr29uIrsHc0zl9X7GqlvbGp53ERd68e+JmobGqk7/HHLfU19IzUNjdTU\nN79GR4UZxEdHkBAdQY+YCBJjIumVEM3QXgkkxkQ2PxfbfN8zNorkuEiS4iJJjosiOS5Kk7KIiMgh\n/LmlPh7Ic85tBTCzRcAMoHWpzwB+2fJ4CfAHMzPn3NE3TzvRB9tK+NnSDW2ui4oIIzo8rPk+IoyY\nyHCiWu6jI8LoGRtJdI9ooiMx3R/GAAAE0ElEQVTDiY0MIzYynNioCGIjw4mLCicmKpy4yHBio5pv\nCdERxEdFEB8dfrDIoyPCdHS4BIUVK1Z4HUFEOsCfpT4AyG+1XABMONoY55zPzMqAVKC49SAzmwPM\nARg4cGCnBZx6el++cEoqURFh/76FhxEZbipbkVbi4uK8jiAiHeDPUm+rFQ/fAu/IGJxz84H5AFlZ\nWZ22FZ8YE0liTGRnvZxIyHr44YcBuO666zxOIiLH4s/rVhYAGa2W04HCo40xswggCSjxYyYROQGL\nFy9m8eLFXscQkXb4s9TXAMPNbIiZRQGzgGWHjVkGXNny+GLgn131fbqIiEio8dvu95bvyK8HVtJ8\nStuTzrkcM7sLyHbOLQP+CDxjZnk0b6HP8lceERGRUOfX89SdcyuAFYc9d0erx7XAJf7MICIi0l34\nc/e7iIiIdCELtq+wzawI2OF1ji6WxmGn+clx02d48vQZnjx9hp2ju32Og5xzvToyMOhKvTsys2zn\nXJbXOYKZPsOTp8/w5Okz7Bz6HI9Ou99FRERChEpdREQkRKjUg8N8rwOEAH2GJ0+f4cnTZ9g59Dke\nhb5TFxERCRHaUhcREQkRKnUREZEQoVIPMmZ2k5k5M0vzOkuwMbPfmtlnZrbBzJ43s55eZwoWZjbV\nzHLNLM/MbvY6T7Axswwze93MPjWzHDP7L68zBSszCzezD81suddZApFKPYiYWQYwBdjpdZYg9Q9g\ntHPuDGATcIvHeYKCmYUDDwHTgFHAd8xslLepgo4PuNE5dyrwBeBH+gxP2H8Bn3odIlCp1IPL74Cf\n0cY156V9zrlXnXO+lsX3aL4csLRvPJDnnNvqnKsHFgEzPM4UVJxzu51z61oeV9BcSgO8TRV8zCwd\n+AbwhNdZApVKPUiY2TeBXc65j7zOEiK+D7zsdYggMQDIb7VcgArphJnZYOAs4H1vkwSleTRv2DR5\nHSRQ+fUqbXJ8zGwV0LeNVb8AbgW+2rWJgs+xPkPn3N9bxvyC5t2hf+7KbEHM2nhOe4tOgJklAEuB\nuc65cq/zBBMzmw7sc86tNbNJXucJVCr1AOKcm9zW82Z2OjAE+MjMoHm38TozG++c29OFEQPe0T7D\nz5nZlcB04AKnSRo6qgDIaLWcDhR6lCVomVkkzYX+Z+fc37zOE4TOBb5pZl8HYoBEM1vonLvc41wB\nRZPPBCEz2w5kOee601WKTpqZTQX+DzjPOVfkdZ5gYWYRNB9YeAGwC1gDXOacy/E0WBCx5v+N/wko\ncc7N9TpPsGvZUr/JOTfd6yyBRt+pS3fyB6AH8A8zW29mj3odKBi0HFx4PbCS5gO8FqvQj9u5wBXA\n+S2/e+tbtjhFOpW21EVEREKEttRFRERChEpdREQkRKjURUREQoRKXUREJESo1EVEREKESl1ERCRE\nqNRFRERChEpdRI7JzK5pNWHKNjN73etMItI2TT4jIh3SMnf5P4H7nHMvep1HRI6kLXUR6agHgX+q\n0EUCl67SJiLtMrPZwCCa54AXkQCl3e8ickxmNo7mK4x9yTlX6nUeETk67X4XkfZcD6QAr7ccLPeE\n14FEpG3aUhcREQkR2lIXEREJESp1ERGREKFSFxERCREqdRERkRChUhcREQkRKnUREZEQoVIXEREJ\nEf8fAff2ts+zZ4kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12bde6d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot sigmoid function\n",
    "z     = np.linspace(-5,5,50)\n",
    "sigma = 1./(1+np.exp(-z))\n",
    "fig,ax= plt.subplots(1,figsize=[8,3])\n",
    "ax.plot(z,sigma);ax.set_xlabel('z');ax.set_ylabel(r'$\\sigma$')\n",
    "ax.axvline([0],color='k',ls='--');ax.axhline([0.5],color='k',ls='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xavier and He Initialization\n",
    "The problem is that the signal needs to be able to flow properly in both directions: in the forward direction when making predictions, and in the reverse when backpropagating gradients. We don't want the signal to vanish or explode/saturate. For this to happen the variance of the outputs needs to be equal to the variance of the inputs, and the gradients need to have equal variance before and after flowing through the layer in the reverse direction.\n",
    "\n",
    "The weights must be initialized randomly where $n_{inputs}$ and $n_{ouputs}$ are the number of input and ouput connections for the layer whose weights are being initialized (called fan-in and fan-out).\n",
    "\n",
    "> Normal distribution with mean 0 and standard deviation $\\sigma = \\sqrt{ \\frac{2}{n_{inputs}+n_{outputs}}  }$\n",
    "\n",
    "> Uniform distribution between $-r$ and $+r$ with $r=\\sqrt{ \\frac{6}{n_{inputs}+n_{outputs}}  }$\n",
    "\n",
    "When the number of input connections is roughly equal to the number of output connections, the above simplifies to $\\sigma=1/\\sqrt{n_{inputs}}$ or $r=\\sqrt{3}/\\sqrt{n_{inputs}}$. Below are the known initializations for different activation functions:\n",
    "\n",
    "| Activation function  |Uniform distribution | Normal distribution   |\n",
    "|---|---|---|\n",
    "|Logistic       | $r=\\sqrt{ \\frac{6}{n_{inputs}+n_{outputs}}  }$  | $\\sigma = \\sqrt{ \\frac{2}{n_{inputs}+n_{outputs}}  }$  |\n",
    "|Hyperbolic tan | $r=4\\sqrt{ \\frac{6}{n_{inputs}+n_{outputs}}  }$  | $\\sigma = 4\\sqrt{ \\frac{2}{n_{inputs}+n_{outputs}}  }$  |\n",
    "|ReLU           | $r=\\sqrt{2} \\sqrt{ \\frac{6}{n_{inputs}+n_{outputs}}  }$  |$\\sigma = \\sqrt{2}\\sqrt{ \\frac{2}{n_{inputs}+n_{outputs}}  }$   |\n",
    "\n",
    "By default, the `fully_connected()` function uses logistic uniform distribution. This can be changed by using the `tf.layers.variance_scaling_initializer()`. With the new api, the `dense()` function has `kernel_initializer` paramter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "# MNIST type input\n",
    "n_inputs=28*28\n",
    "n_hidden1= 300\n",
    "# Placeholders\n",
    "X=tf.placeholder(tf.float32,shape=(None,n_inputs),name='X')\n",
    "# Change intializer\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "hidden1 = tf.layers.dense(X,n_hidden1,activation=tf.nn.relu,\n",
    "                         kernel_initializer=he_init,name='hidden1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonsaturating Activation Functions\n",
    "Since it was known that the brain's neurons use sigmoid shaped activation functions, it was thought they were the best choice for ANNs. However other activation functions behave better in DNNs, with ReLU activation function being a good choice because it does not saturate for positive values.\n",
    "\n",
    "ReLU activation has problems though, it suffers from *dying* ReLUs during training where some neurons effectively die, meaning they stop outputting anything other than 0. During training, if a neuron's weights get updated such that the weighted sum of the neuron's inputs is negative, it will start outputting 0. When this happens the neuron is unlikely to come back to life as the gradient is 0.\n",
    "\n",
    "To solve this issue a **Leaky ReLU** can be used where the function is defined as: $ReLU_{\\alpha}(z) = \\max(\\alpha z, z)$. The hyperparameter $\\alpha$ determines how much the function leaks, it is the slope of the function for $z<0$, and is typically set to 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x12f7b09e8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAADTCAYAAAC7kdtbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl4lOW5x/HvTQIkyCZbRXYUWUQI\nkIRErEVb17pVpdVaWVyQFrVirWtbq4fT1qXUolYFWS2CiCJYUXFraStbgmENEkCEALIbtiQkmef8\nMQMnhIRMyGTemcnvc125ZnvemfuZl/DLu8zc5pxDREREIkcdrwsQERGR4ymcRUREIozCWUREJMIo\nnEVERCKMwllERCTCKJxFREQijMJZREQkwiicRUREIozCWUREJMLEe/XCLVq0cB07dvTq5UVERMIu\nMzNzt3OuZWXjPAvnjh07kpGR4dXLi4iIhJ2ZfR3MOO3WFhERiTAKZxERkQhTaTibWTsz+8zMss1s\ntZn9spwxZmZjzWy9ma0ws741U66IiEjsC+aYczHwK+fcMjNrBGSa2UfOuTWlxlwBdAn89AdeClxW\nSVFREbm5uRQUFFR1UamGhIQE2rZtS926db0uRURECCKcnXPbge2B6wfMLBtoA5QO52uBqc7fHHqR\nmTU1s9aBZYOWm5tLo0aN6NixI2ZWlUXlFDnn2LNnD7m5uXTq1MnrckREIsLaxfM5+N9X6HPvG8TF\nh//c6SodczazjkAfYHGZh9oAW0rdzg3cV3b54WaWYWYZu3btOuH5CwoKaN68uYI5jMyM5s2ba2+F\niAhwpLCAhePupcu8H9P6wEp2bt3gSR1Bh7OZNQTeAu5zzu0v+3A5i7gT7nBunHMu2TmX3LJl+R/z\nUjCHn95zERHYlJ3BlqfTSd82hcxmP6TJqMW07tDVk1qC2lY3s7r4g3mac+7tcobkAu1K3W4LbKt+\neSIiIjXLV1LCkjf+QJ8v/8ohSyRrwEukXvJTT2sK5mxtAyYA2c65MRUMmwsMDpy1nQbkVfV4c6SI\ni4sjKSmJnj17cvXVV/Ptt99WukzDhg1PuG/o0KHMmjWr0nEiIuKdb7asZ83TF5O27lmyT0vGN+Jz\nkjwOZghut/YA4FbgYjPLCvxcaWYjzGxEYMw8YCOwHhgP/KJmyq15iYmJZGVlsWrVKpo1a8aLL77o\ndUkiIlIDMt59hQYTvkvngmyWnPd7ej8wjxZntKt8wTAI5mzt/1D+MeXSYxwwMlRFATzx7mrWbCt7\naLt6epzZmMevPjfo8enp6axYseLY7WeeeYaZM2dSWFjIj370I5544omQ1iciIjUvb88O1k8eQfKB\nT1kb351GP51AaufgsyEc9A1hFSgpKeGTTz7hmmuuAWD+/Pnk5OSwZMkSsrKyyMzMZMGCBR5XKSIi\nVbFywWwKn0+j1/5/sbDDCM5+aAFtIiyYwcPGF5WpyhZuKOXn55OUlMSmTZvo168fl1xyCeAP5/nz\n59OnTx8ADh48SE5ODhdeeGG5z1PeGdA6K1pExBsFhw+SNek+0na9ydd12pJ3zVTSk77rdVkVithw\n9srRY855eXlcddVVvPjii9x7770453jkkUe46667gnqe5s2bs2/fvmO39+7dS4sWLWqqbBERqUBO\n1r+pN3cEab5cFrUcRNKw50hoENkn6Gq3dgWaNGnC2LFjefbZZykqKuKyyy5j4sSJHDx4EICtW7ey\nc+fOCpcfOHAgb7zxBkeOHAFg8uTJXHTRRWGpXUREoLjoCAsnP0zH2deS6DvMyosnkzby1YgPZtCW\n80n16dOH3r17M2PGDG699Vays7NJT08H/B+L+vvf/06rVq04fPgwbdu2Pbbc/fffz/33309mZib9\n+vUjLi6Os846i5dfftmrqYiI1CpbN67mwOu3k16cTWbjizh76Cuc1/w7XpcVNPOfaB1+ycnJLiMj\n47j7srOz6d69uyf11HZ670UkFjifj6VvP0fPlX+i2OJYl/wEyVcN97qsY8ws0zmXXNk4bTmLiEhM\n2P3NFnKn3EFq/iJWJSTR4mcTSG53ttdlnRKFs4iIRL0v5v+dDp8/QneXz6KuD5D6k0epExfndVmn\nTOEsIiJR6+D+fayZNJLUfe+xIa4z+28cT1r3SvcaRzyFs4iIRKW1i+fT+IO7SfbtZGGbwfQb8gz1\n6id4XVZIKJxFRCSqHCksIHPqQ6TmTmFHnZZ8eeUbpPe/zOuyQkrhLCIiUePr7EyKZt1JeskGlpx+\nJd2HvciZTZp5XVbI6UtIyghFW8fJkydz9913n9Kyv//972nTpg1JSUn06NGD6dOnB7XMs88+e9x9\nmzZtomfPnpWOExGJBr6SEha9PpozZlxG85JdfHH+i6TeN51GMRjMoHCOSKNGjSIrK4s5c+Zw1113\nUVRU5HVJIiKe2ZG7IdBz+RmyG/SjZMTn9Ln0Z16XVaMid7f2+w/DNytD+5xnnAdX/KnKi+3atYsR\nI0awefNmAJ577jkGDBjAkiVLuO+++8jPzycxMZFJkybRtWvX45Z97733GD16NDNnzuTCCy9k3bp1\n1K1bl/3799OrVy9ycnKoW7duua/bpUsXGjRowL59+2jVqhUbNmxg5MiR7Nq1iwYNGjB+/Hi6detW\n9fdBRCRKZLw3nnOWPk5nV8yS8x4n5fr7sDqxv10ZueEcQX75y18yatQoLrjgAjZv3sxll11GdnY2\n3bp1Y8GCBcTHx/Pxxx/z6KOP8tZbbx1bbvbs2YwZM4Z58+Zx+umnM3DgQN577z2uu+46ZsyYwQ03\n3FBhMAMsW7aMLl260KpVKwCGDx/Oyy+/TJcuXVi8eDG/+MUv+PTTT2t8/iIi4Za3dxc5k+4i+cAn\nfBnfjdNumkDq2T0rXzBGRG44n8IWbk35+OOPWbNmzbHb+/fv58CBA+Tl5TFkyBBycnIws+N2P3/2\n2WdkZGQwf/58GjduDMAdd9zB008/zXXXXcekSZMYP358ua/3l7/8hfHjx7Nx40Y++OADwN+i8vPP\nP2fQoEHHxhUWFlZYc0XtKdW2UkQi3ap/z6HVJ/fR2+WxsNPPSbnlSeLr1vO6rLCK3HCOID6fj4UL\nF5KYmHjc/ffccw8XXXQRs2fPZtOmTQwcOPDYY507d2bjxo2sW7eO5GT/B+IHDBjApk2b+Ne//kVJ\nSckJJ2wdNWrUKB544AHefvttBg8ezIYNG/D5fDRt2pSsrKygai7bshL8bSs7depUhZmLiIRPweGD\nZE0eRdrOmWyu04ZNV08hvc+FXpflidjfcR8Cl156KS+88MKx20cDMi8vjzZt2gD+M7RL69Chw7Fw\nXb169bH7Bw8ezM0338ywYcMqfd3rr7+e5ORkpkyZQuPGjenUqRNvvvkmAM45li9fXuGyDRs2pHXr\n1nzyySeAP5g/+OADLrjgguAmLSISRuuX/4cdz6aRtnMmi1veSMtfLaZLLQ1mUDif4Gj7x6M/Y8aM\nYezYsWRkZNCrVy969OhxrPXjgw8+yCOPPMKAAQMoKSk54bm6du3KtGnTGDRoEBs2bADglltuYd++\nfdx8881B1fO73/2OMWPG4PP5mDZtGhMmTKB3796ce+65zJkz59i40aNHH1c3wNSpUxk9ejRJSUlc\nfPHFPP7445x11lnVfYtEREKmpLiYRZMfpcPb15DoO8TKiybRf+QEEk9r5HVpnlLLyDCbNWsWc+bM\n4bXXXvO6lOPUhvdeRCLL1o3ZHJh+G92K1pDZcCBnDxtHkyjquXwq1DIyAt1zzz28//77zJs3z+tS\nREQ843w+ls4ey7kr/kgjq0NGv6fp98M7a8VHpIKlcA6j559/3usSREQ8tWdHLpun3Enq4c+jvudy\nTYq4cHbO6eM+YebVoQ0RqV2yPnqd9v99iB4un0Xn/IrUmx6L6p7LNSmiwjkhIYE9e/bQvHlzBXSY\nOOfYs2cPCQmx0WZNRCKPv+fy3aTu+wcb4jqRd8N40nqkeF1WRIuocG7bti25ubns2rXL61JqlYSE\nhGNneIuIhNLaJR/R6P2Rx3ou9x38FPUTGnhdVsSrNJzNbCJwFbDTOXfCt2aY2UBgDvBV4K63nXNP\nnkoxdevW1ZdkiIjEgLI9l9deMYP0tMu9LitqBLPlPBl4AZh6kjH/ds5dFZKKREQkqtWWnss1qdJw\nds4tMLOONV+KiIhEM19JCUtm/omktX8h3xJZlv4CqZfd6nVZUSlUx5zTzWw5sA14wDm3urxBZjYc\nGA7Qvn37EL20iIh4bUfuBna+djtphV+wvEEqbYZMoO8Z+n/+VIXiE9/LgA7Oud7A88A7FQ10zo1z\nziU755JbtmwZgpcWERGvZb73KomvfpezCtaw+Nzf0uvXH9JCwVwt1d5yds7tL3V9npn9zcxaOOd2\nV/e5RUQkcuXt3UXO5BEk7/+YL+O70uCmCfQ/+zyvy4oJ1Q5nMzsD2OGcc2aWin9rfE+1KxMRkYi1\n6t9zaPnJKJLcPhZ2HEHKz/6n1vVcrknBfJRqOjAQaGFmucDjQF0A59zLwI3Az82sGMgHbnL6yikR\nkZhUkH+IrEmjSNv5BpvrtGHjVe+Q3vd7XpcVc4I5W/ukvQ2dcy/g/6iViIjEsPXL/0v8nLtI821h\ncYsb6DXsr7W+tWNNiahvCBMRkchTUlzMkmmP02/jS+RZY1YMnEj/gTd4XVZMUziLiEiFtm7MZv/0\n20gvWsOyRt+j89Bx9GpxhtdlxTyFs4iInMD5fGS88zw9lv/B33O571P0u2q4ei6HicJZRESOc7Tn\ncsrhz1ldvzfNfzaB5PZdvC6rVlE4i4jIMVmfzKDdvx/kXHeIRefcT+pNv1HPZQ8onEVEhEMHvmX1\npLtJ3fsuG+t0ZP+Nb6nnsocUziIitdzapR/TcN5Ikn07WHjmYPoOUc9lrymcRURqqaIjhWRMfZjU\nLZPYaS3UczmCKJxFRGqhr9cu48ibd5Jesp6lp19Bt2F/o7V6LkcMhbOISC3i77n8FElrx5BvCXyR\nPpaUy4Z4XZaUoXAWEakldm79ih1TbyOtcNmxnst91NoxIimcRURqgcz3XuXspb/jLFfM4nN/Q+qN\nv9IXikQwhbOISAzL27ebnEl3kbz/Y9bFn0PiT16lf5feXpcllVA4i4jEqFX/mUvLj+/z91zucBcp\nt45Wz+UooXAWEYkxBfmHyJp8P2k7ZrDFzmTjNeq5HG0UziIiMWTDis+Je+cu0nybWdzienoNG6ue\ny1FI4SwiEgNKiotZ8voT9NvwIvutESu+N4H+F93odVlyihTOIiJRbttXa8l7/TbSi1azrOGFdBo6\njl4tW3tdllSDwllEJEo5n4+lc17g3Kz/pTHG0j5/IPman+sjUjFA4SwiEoX27tzK11OGk3roP6yp\nfx6n3zKBlA5dvS5LQkThLCISZZZ/OpM2C37Nue4gi7rcR8pNvyUuXv+dxxKtTRGRKHH4YB4rJ91L\n/z3v8FWdjuy/fiZpPft7XZbUAIWziEgUWJvxCQ3fG0mK7xsWtb6FPkOfVc/lGKZwFhGJYEVHCsmc\n+ggpWyb6ey5fPp209Cu8LktqmMJZRCRCff1lFkdm3k5ayXqWNr2MrsNeonXT5l6XJWGgcBYRiTDO\n52PJzKfonf1n8i2BZWl/JeXyoV6XJWGkcBYRiSC7tm1i+9Tb6F+QyfLEFNoMnkDfMzt4XZaEWaWf\nVDeziWa208xWVfC4mdlYM1tvZivMrG/oyxQRiX2Z8yZRb9z5dMlfyeIej9Hrwfm0UDDXSsFsOU8G\nXgCmVvD4FUCXwE9/4KXApYiIBMHfc3kEyfs/Us9lAYIIZ+fcAjPreJIh1wJTnXMOWGRmTc2stXNu\ne4hqFBGJWav++y4tPrqPJLeXhR2Gk/yz0dStV9/rssRjoTjm3AbYUup2buC+E8LZzIYDwwHat28f\ngpcWEYlO/p7LvyJtx/RAz+XZpPcd6HVZEiFCEc5Wzn2uvIHOuXHAOIDk5ORyx4iIxLoNKxdRZ/Zw\n0nxfs7jF9Zw39DkaNGzidVkSQUIRzrlAu1K32wLbQvC8IiIxpaS4mKWvP0HfQM/l5d97lf4XDfK6\nLIlAoQjnucDdZjYD/4lgeTreLCJyvG2bvuTb128n7cjKYz2Xe6vnslSg0nA2s+nAQKCFmeUCjwN1\nAZxzLwPzgCuB9cBhYFhNFSsiEm2cz0fG3L/R/YvRNAb1XJagBHO29s2VPO6AkSGrSEQkRuzbtZ2v\nJt9JyqF/q+eyVIm+IUxEpAYc7bncUz2X5RToX4qISAip57KEgsJZRCREvsz4lAbvjSTFt109l6Va\nFM4iItVUdKSQjNceI2XzBHZbc7IvnUbagB96XZZEMYWziEg1bF6XRcHMO0kvXsfSppfSddjLnKGe\ny1JNCmcRkVPgfD6WvPkMvdY8S6HVY1n/50i5Qp8kldBQOIuIVNHubV+zbert9C9YyorEFM5Uz2UJ\nMYWziEgVLPtgMp0XPUYXd4TFPR4lddCv9YUiEnIKZxGRIOz/dg9fTvo5KXkfsi7+HBJ+PJ7+5yR5\nXZbEKIWziEglVn8+j+bz76WP28PC9neSfOv/quey1CiFs4hIBQoLDvPF5AdI3f462+qcwfqrZpGe\n/H2vy5JaQOEsIlKOjasWY28PJ823icUtruO8YWNpq57LEiYKZxGRUkqKi1k6/Un6rn+R/daQ5ReO\np//FP/a6LKllFM4iIgGley5/0fACOgwZR+9WbbwuS2ohhbOI1Hr+nssv0f2L/6ExsCRpNCnXjtRH\npMQzCmcRqdX8PZeHk3JoAWvq9aTpTyeQ2qmb12VJLadwFpFaa/lnb9LmXw/Q0x1g0Vn3kvLTx9Vz\nWSKC/hWKSK1zfM/lDuT96A3SzkvzuiyRYxTOIlKrHNdz+YybSRr6ZxIST/O6LJHjKJxFpFY4vudy\nM9Zc+hppA672uiyRcimcRSTmbclZTv4bdxzruXzO0JfoeXoLr8sSqZDCWURilvP5WDLrWXqtfoYj\nVpfM1OdIuVI9lyXyKZxFJCbt3vY1W4/1XO5H68ET6XdmR6/LEgmKwllEYs6yDybTadFvOMcVsrjH\nI6QOelBfKCJRReEsIjGjdM/lnPgu1Bv0Kv27queyRB+Fs4jEhDUL3+f0D++hr9vNona302/wH9Vz\nWaJWUPt5zOxyM/vSzNab2cPlPD7UzHaZWVbg547QlyoicqLCgsMsfGUk3T64mRKLJ+fqt0i7Y4yC\nWaJapVvOZhYHvAhcAuQCS81srnNuTZmhbzjn7q6BGkVEyvXV6sW4t4aT7tvE4ubX0HPY87Rt1NTr\nskSqLZjd2qnAeufcRgAzmwFcC5QNZxGRsPCVlLBk+v/QN+f5QM/lV+h/8U1elyUSMsGEcxtgS6nb\nuUD/csbdYGYXAuuAUc65LWUHmNlwYDhA+/btq16tiNR627/+kr3T7iDtyAq+OG0AHYaOV89liTnB\nHHO2cu5zZW6/C3R0zvUCPgamlPdEzrlxzrlk51xyy5Ytq1apiNRqzudj6Zy/0XDi9+hQmMOS3qNJ\neuAfNFMwSwwKZss5F2hX6nZbYFvpAc65PaVujgeeqn5pIiJ+3+7+ho2T7yTl4AKy651Lk59OVM9l\niWnBbDkvBbqYWSczqwfcBMwtPcDMWpe6eQ2QHboSRaQ2W/HZLIpeSKPngf+ysPO9nPPQAs5UMEuM\nq3TL2TlXbGZ3Ax8CccBE59xqM3sSyHDOzQXuNbNrgGJgLzC0BmsWkVog/9ABVky6l/6732ZTnfbs\nv+510nud73VZImFhzpU9fBweycnJLiMjw5PXFpHItm7ZP0l89+e0c9tY9B31XJbYYWaZzrnkysbp\nG8JEJGIUFx1h6Wu/IeXr8ey2Zqz6wWukXXCN12WJhJ3CWUQiwpb1K8mfcRvpxevIaHIJXYa9rJ7L\nUmspnEXEU87nY8lbYzhv1dMUWTyZqWNIvvJ2r8sS8ZTCWUQ8s/ubzWydcjv985ewIrEfZ9w6gX5t\nOnldlojnFM4i4okvPpxCx4WP0dUVsLj7w6QMepA6cXFelyUSERTOIhJWB/L2snbSL0j59n1y4s6m\n3o8nqOeySBkKZxEJG/VcFgmOwllEalxhwWGWTfk1/bdNY1ud75Dzw1mkpfzA67JEIpbCWURq1Fdr\nluJ7607SS75Sz2WRICmcRaRGlO65fMBOI+uCl+n/g5u9LkskKiicRSTkvtmcw56/3xbouXw+HYa+\nSpJaO4oETeEsIiHjfD4y//EKXTOfoBGOpb2fJPm6e7A6wTTAE5GjFM4iEhJ5e3awYdKdJB/8F9n1\netD45omkdO7udVkiUUnhLCLVtuKfb9H6n7+ip9vPws53k3rLE8TF678XkVOl3x4ROWX+nsu/pP/u\nt9hUpx15104jvfcAr8sSiXoKZxE5JTlfLKD+uyPo79vKolY/IWnYX9RzWSREFM4iUiXFRUdY+vff\nkrxpPHutKau+P5W0717rdVkiMUXhLCJB27J+JYdn3E568ZdkNPkBXYa9op7LIjVA4SwilSrdc7mJ\nxZOZ8meSf3iH12WJxCyFs4icVOmeyysT+vKdwRPVc1mkhimcRaRCyz58jU4LH6Wry2dRt4dI/fFD\n6rksEgYKZxE5wYG8vWRPGknqt/NYH3cWdQe9Slq3vl6XJVJrKJxF5DhrFn1A0w/voZ9vFwvb3Ua/\nW/9IvfoJXpclUqsonEUEgCMF+Syb+iCpW1/z91y+ahbp6rks4gmFs4gc67mcVvIVS5pfzbnDXlDP\nZREPKZxFarH8QwdZPvvZ43oup6rnsojnggpnM7sc+CsQB7zqnPtTmcfrA1OBfsAe4CfOuU2hLVVE\nQqGouJiVn79PYebr9Pz2M9Isny9OO5/2Q8aT9J22XpcnIgQRzmYWB7wIXALkAkvNbK5zbk2pYbcD\n+5xzZ5vZTcBTwE9qomARqTqfz7E8K4N9i6bSbef79GUXh0hg7ekDqZ98C0nnX6WeyyIRJJgt51Rg\nvXNuI4CZzQCuBUqH87XA7wPXZwEvmJk551wIa63Q9rx85q/eEY6XEok45kqIKykkzldAfEkhcb5C\n4koKiPf5r/t2ZtNuy7v0cTmUOGNdw2T29nyIc753E/0aNPK6fBEpRzDh3AbYUup2LtC/ojHOuWIz\nywOaA7tLDzKz4cBwgPbt259iySf6atchHp+7OmTPJ3KqDB/1KSKBIyRwhPr2/9cTKCLBAvdz5Nj1\nso/5lzs6LrB86ecx//31A7frWUmldW2p15nV5zxIp4uH0L2Zdl2LRLpgwtnKua/sFnEwY3DOjQPG\nASQnJ4dsqzq5YzOW/faSUD2dxArnoKQQKy6A4gIs8OO/ng9Fpe/LP/F6UUFg+fz/X76oAEpKPU9R\nwfGPlxSeerl14iE+ARefiItPCFxPwMU3gPhEXN2EUvcnQnwCJfEJHD5ubIJ/bHwCxNfHxSdSr8kZ\ntDuzewjfWBGpacGEcy7QrtTttsC2Csbkmlk80ATYG5IKg1Avvg7N4uuF6+XkVDgHvmIo8gfZCZfF\nBVDkD8byLwvKX66yZU78GzE4VgfiE6FuQjmXCZDY2H9ZNxHi65c/5tjjQVzGJ2Bx/l/H8v7SFZHa\nJZhwXgp0MbNOwFbgJuCnZcbMBYYAC4EbgU/DdbxZTpGvpEzQFZ4k5EpdFhdWHLCVBabznXq98YEQ\nLC/cEppCo8RSgVjFYKxbdtlEiKsLppgUEW9UGs6BY8h3Ax/i/yjVROfcajN7Eshwzs0FJgCvmdl6\n/FvMN9Vk0THHuaqFXFABWcFzHV3WV3Tq9cbVO34LsXTI1WsIDVpUsMVZwTIVBeTRy/j6CkoRqVWC\n+pyzc24eMK/Mfb8rdb0AGBTa0jziHJQcqTzsKgzPyoKynC3UahynpE78SXapJvi3Kk8alOVcVrSF\nGl/ff72OuhKJiNSk2PiGsAPfwIbPqrA7tpIt0VAdpywbcqe1rEYwVrBVGRcbq1BERP5fbPzPvmst\nvDPixPtPdlJO6eOUwQRkeeNOCEodpxQRkeqLjXBumwr3fnFiGCsoRUQkCsVGONdrAM06e12FiIhI\nSOjLdEVERCKMwllERCTCKJxFREQijMJZREQkwiicRUREIox59RXYZrYL+DqET9mCMi0qo5jmEpli\nZS6xMg/QXCJVrMylJubRwTnXsrJBnoVzqJlZhnMu2es6QkFziUyxMpdYmQdoLpEqVubi5Ty0W1tE\nRCTCKJxFREQiTCyF8zivCwghzSUyxcpcYmUeoLlEqliZi2fziJljziIiIrEilracRUREYoLCWURE\nJMJEbTib2TNmttbMVpjZbDNrWsG4y83sSzNbb2YPh7vOYJjZIDNbbWY+M6vwtH0z22RmK80sy8wy\nwlljsKowl2hYL83M7CMzywlcnl7BuJLAOskys7nhrrMilb3HZlbfzN4IPL7YzDqGv8rgBDGXoWa2\nq9R6uMOLOitjZhPNbKeZrargcTOzsYF5rjCzvuGuMVhBzGWgmeWVWie/C3eNwTCzdmb2mZllB/7v\n+mU5Y8K/XpxzUfkDXArEB64/BTxVzpg4YAPQGagHLAd6eF17OXV2B7oC/wSSTzJuE9DC63qrO5co\nWi9PAw8Hrj9c3r+xwGMHva71VN5j4BfAy4HrNwFveF13NeYyFHjB61qDmMuFQF9gVQWPXwm8DxiQ\nBiz2uuZqzGUg8A+v6wxiHq2BvoHrjYB15fz7Cvt6idotZ+fcfOdcceDmIqBtOcNSgfXOuY3OuSPA\nDODacNUYLOdctnPuS6/rCIUg5xIV6wV/TVMC16cA13lYS1UF8x6Xnt8s4PtmZmGsMVjR8u+lUs65\nBcDekwy5Fpjq/BYBTc2sdXiqq5og5hIVnHPbnXPLAtcPANlAmzLDwr5eojacy7gN/181ZbUBtpS6\nncuJb3o0ccB8M8s0s+FeF1MN0bJevuOc2w7+X2CgVQXjEswsw8wWmVmkBHgw7/GxMYE/dPOA5mGp\nrmqC/fdyQ2CX4ywzaxee0kIuWn43gpVuZsvN7H0zO9frYioTOLTTB1hc5qGwr5f4mnzy6jKzj4Ez\nynnoMefcnMCYx4BiYFp5T1HOfZ58diyYuQRhgHNum5m1Aj4ys7WBv17DKgRziYr1UoWnaR9YL52B\nT81spXNuQ2gqPGXBvMcRsx5KPPY8AAAC/klEQVQqEUyd7wLTnXOFZjYC/x6Bi2u8stCLlnUSjGX4\nv0f6oJldCbwDdPG4pgqZWUPgLeA+59z+sg+Xs0iNrpeIDmfn3A9O9riZDQGuAr7vAgcGysgFSv8F\n3RbYFroKg1fZXIJ8jm2By51mNhv/7r6wh3MI5hIV68XMdphZa+fc9sAurJ0VPMfR9bLRzP6J/y9v\nr8M5mPf46JhcM4sHmhCZuykrnYtzbk+pm+Pxn4cSjSLmd6O6Sgecc26emf3NzFo45yKuIYaZ1cUf\nzNOcc2+XMyTs6yVqd2ub2eXAQ8A1zrnDFQxbCnQxs05mVg//SS8RczZtVZjZaWbW6Oh1/CfElXuW\nZBSIlvUyFxgSuD4EOGGvgJmdbmb1A9dbAAOANWGrsGLBvMel53cj8GkFf+R6rdK5lDn+dw3+44bR\naC4wOHB2cBqQd/TQSrQxszOOnsNgZqn482bPyZcKv0CNE4Bs59yYCoaFf714fabcqf4A6/EfA8gK\n/Bw96/RMYF6pcVfiP/tuA/7drp7XXs5cfoT/L7NCYAfwYdm54D9TdXngZ3U0zyWK1ktz4BMgJ3DZ\nLHB/MvBq4Pr5wMrAelkJ3O513Sd7j4En8f9BC5AAvBn4XVoCdPa65mrM5Y+B34vlwGdAN69rrmAe\n04HtQFHg9+R2YAQwIvC4AS8G5rmSk3x6w+ufIOZyd6l1sgg43+uaK5jHBfh3Ua8olSdXer1e9PWd\nIiIiESZqd2uLiIjEKoWziIhIhFE4i4iIRBiFs4iISIRROIuIiEQYhbOIiEiEUTiLiIhEGIWzSC1h\nZiNK9db9ysw+87omESmfvoREpJYJfI/wp8DTzrl3va5HRE6kLWeR2uev+L9HW8EsEqEiuiuViISW\nmQ0FOuD/3mMRiVDarS1SS5hZP/x9jr/rnNvndT0iUjHt1hapPe4GmgGfBU4Ke9XrgkSkfNpyFhER\niTDachYREYkwCmcREZEIo3AWERGJMApnERGRCKNwFhERiTAKZxERkQijcBYREYkw/wd21TDq70q/\nlwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12f400550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ReLU vs Leaky ReLU\n",
    "z     = np.linspace(-2,2,50)\n",
    "def relu(z):\n",
    "    return np.maximum(z,0)\n",
    "def leaky_relu(z,alpha=0.01):\n",
    "    return np.maximum(z,alpha*z)\n",
    "fig,ax= plt.subplots(1,figsize=[8,3])\n",
    "ax.plot(z,relu(z),label='ReLU'); ax.plot(z,leaky_relu(z,0.05),label='Leaky ReLU')\n",
    "ax.set_xlabel('z'); ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The small slope of the leak, ensures that the leaky ReLUs never die; they can go into a long coma, but they have a chance to eventually wake up. The leaky variants always outperformed the ReLU activation function. \n",
    "\n",
    "Another activation function called the exponential linear unit (ELU) was found to outperform the ReLU variants in some experiments. It is represented as:\n",
    "\n",
    "$ELU_\\alpha(z) = \\left\\{\n",
    "\\begin{array}{l,c,l}\n",
    "      \\alpha(\\exp(z)-1),& if& z <  0 \\\\\n",
    "      z, &if  z \\geq  0 \\\\\n",
    "\\end{array} \n",
    "\\right.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x12f8edba8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAADTCAYAAACoRpuvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFN4iIiJh5v8DupO/vG5ODqwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12f75ef98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def elu(z,alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)\n",
    "\n",
    "fig,ax= plt.subplots(1,figsize=[8,3])\n",
    "ax.plot(z,relu(z),label='ReLU'); ax.plot(z,leaky_relu(z,0.05),label='Leaky ReLU')\n",
    "ax.plot(z,elu(z),label='ELU')\n",
    "ax.set_xlabel('z'); ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different from the ReLU, the ELU:\n",
    "1. Has negative values when $z<0$ which allows the unit to have an average output closer to 0. Helps alleivate the vanishing gradient problem. The hyperparameter $\\alpha$ defines the value that the ELU function approaches when $z$ is large and negative. It is usually set to 1, but can be tweaked.\n",
    "2. Has a nonzero gradient for $z<0$, which avoids the dying issue.\n",
    "3. Is smooth everywhere, including around 0, which helps speed up Gradient Descent as it does not bounce as much around $z=0$.\n",
    "\n",
    "The disadvantage is that it is slower to compute the activation function (due to the exponential), but this is compensated by faster convergence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Which Activation Function to choose for hidden layers? In general ELU > leaky ReLU > ReLU > tanh > logistic. If runtime needs to be fast then leaky ReLU might be better than ELU. If you don't want to tweak any hyperparameters you can use the default $\\alpha$ of 0.01 for leaky ReLU and 1 for ELU. \n",
    "\n",
    "Below we show an example on the MNIST data using the ELU activation function with he_initialization. Note that there is an ELU activation function in `tf.nn.elu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "0  Train accuracy:  0.84 \t Test accuracy:  0.906\n",
      "10  Train accuracy:  0.96 \t Test accuracy:  0.951\n",
      "20  Train accuracy:  0.94 \t Test accuracy:  0.9643\n",
      "30  Train accuracy:  1.0 \t Test accuracy:  0.9707\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def elu(z,alpha=1,name=None):\n",
    "    return tf.where(z < 0, alpha*(tf.exp(z) - 1), z,name=name)\n",
    "\n",
    "# MNIST input data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "n_inputs = 28*28 # number of pixels\n",
    "n_hidden1 = 300; n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "# Placeholders for training data\n",
    "X = tf.placeholder(tf.float32, shape=(None,n_inputs),name='X')\n",
    "y = tf.placeholder(tf.int64, shape=(None),name='y')\n",
    "# Change intializer\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "# Neural Network\n",
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = tf.layers.dense(X,n_hidden1,name= \"hidden1\",activation=elu,kernel_initializer=he_init)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name='hidden2',activation=elu,kernel_initializer=he_init)\n",
    "    logits  = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "# Loss Function\n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "    loss  = tf.reduce_mean(xentropy,name='loss')\n",
    "# Minimize Cost Function\n",
    "eta = 0.01\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(eta)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "# Evaluation\n",
    "with tf.name_scope('eval'):\n",
    "    # Find whether the top logit (prediction) is the same as y, returns boolean of instances\n",
    "    correct = tf.nn.in_top_k(logits,y,1) \n",
    "    # Determine accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "# Initialize all variables and create a SAver\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Execution\n",
    "# Epochs and batch size\n",
    "n_epochs = 40\n",
    "batch_size= 50\n",
    "# Train the model\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples//batch_size): #integer division\n",
    "            # Grab batch\n",
    "            X_batch,y_batch = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization\n",
    "            sess.run(training_op,feed_dict={X:X_batch,y:y_batch})\n",
    "        # Accuracy\n",
    "        acc_train = accuracy.eval(feed_dict={X:X_batch,y:y_batch})\n",
    "        acc_test  = accuracy.eval(feed_dict={X:mnist.test.images,y:mnist.test.labels})\n",
    "        if epoch % 10 == 0:\n",
    "            print(epoch,' Train accuracy: ', acc_train, '\\t Test accuracy: ', acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization\n",
    "\n",
    "Although using He intialization along with ELU (or ReLU) can reduce the vanishing/exploding gradients problem. at the beggining of training. It doesnt' guarantee they won't come back during training.\n",
    "\n",
    "Batch Normalization is a technique that consists of adding an operation in the model just before the activation function of each layer, simply zero-centering and normalizing the inputs, then scaling and shifting the result using two new parameters per layer (one for scaling, and one for shifting). This lets the model learn the optimal scale and mean of the inputs for each layer.\n",
    "\n",
    "To zero-center and normalize the inputs, the algorithm needs to estimate the inputs' mean and standard deviation. It does this by evaluating the mean and standard deviation of the inputs over the current mini-batch. The operation is summarized below:\n",
    "\n",
    "1. $\\mu_B = \\frac{1}{m_B} \\sum\\limits_{i=1}^{m_B} \\textbf{x}^{(i)} $ , $\\mu_B$ is the empirical mean, evaluated over the whole mini-batch, $B$, with $m_B$ the size of the mini-batch.\n",
    "2. $\\sigma_B^2 = \\frac{1}{m_B} \\sum\\limits_{i=1}^{m_B}(\\textbf{x}^{(i)}-\\mu_B)^2 $, $\\sigma_B$ is the empirical standard deviation evaluated over the whole mini-batch.\n",
    "3.  $\\chi^{(i)} = \\frac{\\textbf{x}^{(i)}-\\mu_B }{\\sqrt{\\sigma_B^2 + \\epsilon} }$,$\\chi^{(i)}$ is the zero-centered and normalized input, and $\\epsilon$ is a tiny number to avoid division by zero (typically $10^{-3}$) known as the smoothing term.\n",
    "4. $\\textbf{z}^{(i)} = \\gamma \\textbf{x}^{(i)} + \\beta$, where $\\beta$ is the shifting parameter and $\\gamma$ is the scaling parameter of the layer. $\\textbf{z}^{(i)}$ is the output of the BN operation: scaled and shifed version of the inputs.\n",
    "\n",
    "At test time, there is no mini-batch to compute the empirical mean and standard deviation, so instead the whole training set's mean and standard deviation is used. In total 4 parameters are learned for each batch-normalized layer: $\\gamma$ (scale), $\\beta$ (offset), $\\mu$ (mean), and $\\sigma$ (standard deviation).\n",
    "\n",
    "This method was found to improve DNN such that the vanishing gradient problem is reduced, less sensitive to the weight initialization, and larger learning rates could be used. BN removes the need for normalizing the input data, since the first hidden layer perform this. However extra computations are needed at each layer incurring computational penalty. So if speed is of utmost importance, better to use ELU + He initialization first.\n",
    "\n",
    "#### Implementing Batch Normalization with TensorFlow\n",
    "TF provides a `batch_normalization()` function that centers and normalizes the inputs but you must compute the mean and standard deviation yourself and pass them as parameters to this function. You must also handle the creation of the scaling and offset parameters and pass them to this function. This is doable but complicated and messy, it is better to use the `batch_norm()` function, which handles all of this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# Placeholders for training data\n",
    "X = tf.placeholder(tf.float32, shape=(None,n_inputs),name='X')\n",
    "y = tf.placeholder(tf.int64, shape=(None),name='y')\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "# Initializer\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "# Hidden Layers\n",
    "hidden1 = tf.layers.dense(X,n_hidden1,name='hidden1')\n",
    "bn1     = tf.layers.batch_normalization(hidden1,training=training,momentum=0.9)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "\n",
    "hidden2 = tf.layers.dense(bn1_act,n_hidden1,name='hidden2')\n",
    "bn2     = tf.layers.batch_normalization(hidden2,training=training,momentum=0.9)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = tf.layers.batch_normalization(logits_before_bn, training=training,\n",
    "                                       momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `training` placeholder can be either `True` or `False` and tells the `batch_normalization` if it should use the current mini-batch's mean and standard deviation (during training) or the running averages that it keeps track of (during testing). The `momentum` parameter is for the exponential decay algorithm used in the running averages. You want high values (e.g. 0.999) for large datasets.  The batch norm is run just before each hidden layer's activation function, the ELU is applied manually after the batch norm layer.\n",
    "\n",
    "We can avoid repeating the above with the python `functools.partial()` function instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "tf.reset_default_graph()\n",
    "# Placeholders for training data\n",
    "X = tf.placeholder(tf.float32, shape=(None,n_inputs),name='X')\n",
    "y = tf.placeholder(tf.int64, shape=(None),name='y')\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "my_batch_norm_layer = partial(tf.layers.batch_normalization,training=training,\n",
    "                             momentum=0.9)\n",
    "hidden1 = tf.layers.dense(X,n_hidden1,name='hidden1')\n",
    "bn1     = my_batch_norm_layer(hidden1)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "\n",
    "hidden2 = tf.layers.dense(bn1_act,n_hidden2,name='hidden2')\n",
    "bn2     = my_batch_norm_layer(hidden2)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = my_batch_norm_layer(logits_before_bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build a neural net for MNIST using ELU activation and Batch Normalization at each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Train accuracy:  0.895 \t Test accuracy:  0.8784\n",
      "2  Train accuracy:  0.95 \t Test accuracy:  0.9157\n",
      "4  Train accuracy:  0.935 \t Test accuracy:  0.9334\n",
      "6  Train accuracy:  0.945 \t Test accuracy:  0.944\n",
      "8  Train accuracy:  0.935 \t Test accuracy:  0.9516\n",
      "10  Train accuracy:  0.975 \t Test accuracy:  0.9551\n",
      "12  Train accuracy:  0.96 \t Test accuracy:  0.9598\n",
      "14  Train accuracy:  0.98 \t Test accuracy:  0.9631\n",
      "16  Train accuracy:  0.97 \t Test accuracy:  0.9642\n",
      "18  Train accuracy:  0.975 \t Test accuracy:  0.9668\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# Placeholders for training data\n",
    "X = tf.placeholder(tf.float32, shape=(None,n_inputs),name='X')\n",
    "y = tf.placeholder(tf.int64, shape=(None),name='y')\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "momentum = 0.9\n",
    "\n",
    "# Neural Net\n",
    "with tf.name_scope('dnn'):\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    \n",
    "    my_batch_norm_layer = partial( tf.layers.batch_normalization,\n",
    "                                 training=training, momentum=momentum)\n",
    "    \n",
    "    my_dense_layer = partial(tf.layers.dense,kernel_initializer=he_init)\n",
    "    \n",
    "    hidden1 = my_dense_layer(X,n_hidden1,name='hidden1')\n",
    "    bn1  = tf.nn.elu(my_batch_norm_layer(hidden1))\n",
    "    hidden2 = my_dense_layer(bn1,n_hidden1,name='hidden2')\n",
    "    bn2  = tf.nn.elu(my_batch_norm_layer(hidden2))\n",
    "    logits_before_bn = my_dense_layer(bn2,n_outputs,name='outputs')\n",
    "    logits = my_batch_norm_layer(logits_before_bn)\n",
    "\n",
    "# Loss Function\n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "    loss  = tf.reduce_mean(xentropy,name='loss')\n",
    "    \n",
    "# Minimize Cost Function\n",
    "eta = 0.01\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(eta)\n",
    "    extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(extra_update_ops):\n",
    "        training_op = optimizer.minimize(loss)\n",
    "\n",
    "# Evaluation\n",
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits,y,1) \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "\n",
    "# Initialize all variables and create a SAver\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Execution\n",
    "# Epochs and batch size\n",
    "n_epochs = 20\n",
    "batch_size= 200\n",
    "# Train the model\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples//batch_size): #integer division\n",
    "            # Grab batch\n",
    "            X_batch,y_batch = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization\n",
    "            sess.run(training_op,feed_dict={training:True, X:X_batch, y:y_batch})\n",
    "        # Accuracy\n",
    "        acc_train = accuracy.eval(feed_dict={X:X_batch,y:y_batch})\n",
    "        acc_test  = accuracy.eval(feed_dict={X:mnist.test.images,y:mnist.test.labels})\n",
    "        if epoch % 2 == 0:\n",
    "            print(epoch,' Train accuracy: ', acc_train, '\\t Test accuracy: ', acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only had 2 layers in this example, it's unlikely that Batch Normalization will have a very positive impact, but for deeper networks it can make a tremendous difference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default DNN configuration:\n",
    "\n",
    "| Configuration | Choice |\n",
    "|---|---|\n",
    "| Initialization  |He Initialization | \n",
    "| Activation function       | ELU | \n",
    "| Normalization| Batch Normalization  | \n",
    "| Optimizer    | Adam |\n",
    "| Learning rate scheduler | None |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The material in this notebook is made available under the [Creative Commons Attribution license](https://creativecommons.org/licenses/by-nc/4.0/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
